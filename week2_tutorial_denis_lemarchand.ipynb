{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "week2_tutorial_denis_lemarchand.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/delemarchand2020/IVADO_MILA_DL/blob/main/week2_tutorial_denis_lemarchand.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mipSoOVlavkb"
      },
      "source": [
        "# IVADO/MILA DEEP LEARNING SCHOOL\n",
        "# Spring 2021\n",
        "# Tutorial : Categorical data with multilayer perceptron (MLP)\n",
        "\n",
        "## Authors: \n",
        "\n",
        "Arsène Fansi Tchango <arsene.fansi.tchango@mila.quebec>\n",
        "\n",
        "Gaétan Marceau Caron <gaetan.marceau.caron@mila.quebec>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLHwvggEZERd"
      },
      "source": [
        "# Preface"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKNGtQkkohiM"
      },
      "source": [
        "This tutorial introduces the practical aspects of Deep Learning through the realization of a simple end-to-end project. We will use the deep learning library <a href=\"https://pytorch.org/\"> `PyTorch`</a>, which is well-known for its ease of use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu9DZNmYpePz"
      },
      "source": [
        "# Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWCNdeTIpkCa"
      },
      "source": [
        "Before we begin, we must install all the required libraries for this part of the tutorial. To do so, we will use the `pip` utility. Execute the cell below by selecting it and pressing `shift`+`Enter`. (This operation may take a few minutes.)\n",
        "\n",
        "We need to be using the latest version of `pillow` for this tutorial. If you are prompted with:\n",
        "\n",
        "> WARNING: The following packages were previously imported in this runtime:\n",
        "  [PIL]\n",
        "You must restart the runtime in order to use newly installed versions.\n",
        "\n",
        "Then click on restart runtime and rerun the cells afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g_0k-_Eppi-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8f0a2c-0de2-47a4-b1d5-dffd5b375b82"
      },
      "source": [
        "!pip3 install torch torchvision matplotlib\n",
        "!pip3 install --upgrade pillow==8.1.0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.9.1+cu101)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision) (8.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already up-to-date: pillow==8.1.0 in /usr/local/lib/python3.7/dist-packages (8.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKufekB4FnqN"
      },
      "source": [
        "To ensure that all required libraries are available, let's try to load all libraries and modules we will need during this tutorial by executing this cell: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loLQlRg3sV-r"
      },
      "source": [
        "import importlib\n",
        "required_libraries = ['torch', 'torchvision', 'PIL', 'matplotlib', \n",
        "                      'numpy', 'pandas']\n",
        "for lib in required_libraries:\n",
        "    if importlib.util.find_spec(lib) is None:\n",
        "        print(\"%s unavailable\" % lib)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FeLUcnk5scNx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dd4b52e-03d9-470c-d09a-13202015e7ad"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if use_gpu else \"cpu\")\n",
        "\n",
        "print(\"Torch version: \", torch.__version__)\n",
        "print(\"GPU Available: {}\".format(use_gpu))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Torch version:  1.8.1+cu101\n",
            "GPU Available: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xc9wc4qq7qob"
      },
      "source": [
        "Fix the seed for the different libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05jTJ12r7msf"
      },
      "source": [
        "seed = 4321\n",
        "np.random.seed(seed) # Set the random seed of numpy for the data split.\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzgFV9Favkt"
      },
      "source": [
        "# PyTorch in a nutshell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vrus_-F0avkt"
      },
      "source": [
        "*PyTorch* is a Python library that supports a vibrant ecosystem of tools and libraries for machine learning (ML) in vision, NLP, and more. It provides two high-level features:\n",
        "<ul>\n",
        "<li> operations on <a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py\">tensors</a> (such as NumPy) with GPU support,</li>\n",
        "<li> operations for creating and optimizing computational graphs with an automatic differentiation system called <a href=\"https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py\">Autograd</a>.</li>\n",
        "</ul>\n",
        "\n",
        "<a href=\"https://pytorch.org/docs/stable/torch.html\">PyTorch docs</a> contain the API documentation and <a href=\"https://pytorch.org/tutorials/\">many tutorials</a>.\n",
        "Also, PyTorch offers several data processing utilities. One of these utilities is the class <a href=\"http://pytorch.org/docs/master/data.html#\"> `torch.utils.data.Dataset`</a> which offers an easy to use interface to handle a data set. For more information, please refer to the following urls: \n",
        "<ul>\n",
        "<li>PyTorch data sets: <a href=\"http://pytorch.org/docs/master/data.html\"> PyTorch - datasets</a>.</li>\n",
        "<li>A tutorial for loading data: <a href=\"http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\"> PyTorch - data loading tutorial</a>.</li>\n",
        "</ul>\n",
        "\n",
        "<a href=\"http://pytorch.org/docs/master/cuda.html#module-torch.cuda\">`torch.cuda`</a> is a package that provides the same functions as CPU tensors but for  CUDA tensors, which are used for GPU computing. <a href=\"http://pytorch.org/docs/master/cuda.html#torch.cuda.is_available\">`torch.cuda.is_available()`</a> returns a boolean indicating if CUDA is currently available. Finally, we recommend using a `device` variable that identifies the device that will perform computations. We can assign a tensor to a device with the method `.to(device)`. By default, the tensors are CPU tensors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm122vNmq92L"
      },
      "source": [
        "# Ingredients for a proof of concept (POC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqvhR0ebavmE"
      },
      "source": [
        "To realize a ML POC, you need:\n",
        "<ul>\n",
        "<li>a task description as well as data to support it,</li>\n",
        "<li>evaluation metrics to assess the performance of models,</li>\n",
        "<li>a model description,</li>\n",
        "<li>a loss function to minimize,</li>\n",
        "<li>an optimizer that adjusts the parameters of the model.</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8_pfpu2f6AO"
      },
      "source": [
        "# How to prepare the dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5piZxYUhSzq"
      },
      "source": [
        "In this tutorial, we study the tragedy of the Titanic through a data-driven approach. Our task is to determine whether or not a passenger survived the Titanic sinking based on passenger data only. The results will show how the passengers' fate was pre-determined by the features selected in this study, without considering other factors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4GuYNDFavlU"
      },
      "source": [
        "## Titanic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiOJx2ytavlU"
      },
      "source": [
        "First, we download the Titanic dataset from the following address:\n",
        "<br/>\n",
        "https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true.<br/>\n",
        "This dataset provides information on the fate of 1309 passengers of the first and only journey of the liner RMS Titanic, summarized by economic status (class), gender, age, family information, and survival. We use this dataset because we can train models very quickly for the purpose of this tutorial. The Kaggle platform also uses this dataset as an introduction to classical machine learning. <br/>\n",
        "\n",
        "Let's take a look at the features and some examples from this dataset. To do so, we use the library <a href=\"https://pandas.pydata.org/\">Pandas</a> to load the dataset into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX_RSiffavlW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        },
        "outputId": "7b9f32ae-b85f-4682-dd18-bf41a787175c"
      },
      "source": [
        "titanic_df = pd.read_csv(\n",
        "    'https://github.com/afansi/winterschool18/blob/master/titanic3.csv?raw=true', \n",
        "    sep='\\t', \n",
        "    index_col=None, \n",
        "    na_values=['NA']\n",
        ")\n",
        "\n",
        "# a snapshot of the first 5 data points\n",
        "titanic_df.head()\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pclass</th>\n",
              "      <th>survived</th>\n",
              "      <th>name</th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>ticket</th>\n",
              "      <th>fare</th>\n",
              "      <th>cabin</th>\n",
              "      <th>embarked</th>\n",
              "      <th>boat</th>\n",
              "      <th>body</th>\n",
              "      <th>home.dest</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allen, Miss. Elisabeth Walton</td>\n",
              "      <td>female</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24160</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>B5</td>\n",
              "      <td>S</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>St Louis, MO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Allison, Master. Hudson Trevor</td>\n",
              "      <td>male</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Miss. Helen Loraine</td>\n",
              "      <td>female</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mr. Hudson Joshua Creighton</td>\n",
              "      <td>male</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>135.0</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Allison, Mrs. Hudson J C (Bessie Waldo Daniels)</td>\n",
              "      <td>female</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>113781</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>C22 C26</td>\n",
              "      <td>S</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Montreal, PQ / Chesterville, ON</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   pclass  survived  ...   body                        home.dest\n",
              "0       1         1  ...    NaN                     St Louis, MO\n",
              "1       1         1  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "2       1         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "3       1         0  ...  135.0  Montreal, PQ / Chesterville, ON\n",
              "4       1         0  ...    NaN  Montreal, PQ / Chesterville, ON\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj88WmCmavlf"
      },
      "source": [
        "Here's the list of the features with their description:\n",
        "\n",
        "<ol>\n",
        "\n",
        "  <li> <b>pclass</b>: Passenger class (1 = first; 2 = second; 3 = third) </li>\n",
        "  <li> <b>survived</b>: Survived? (0 = no; 1 = yes) </li>\n",
        "  <li> <b>name</b>: Name </li>\n",
        "  <li> <b>sex</b>: Sex </li>\n",
        "  <li> <b>age</b>: Age </li>\n",
        "  <li> <b>sibsp</b>: Number of brothers, sisters, or spouses onboard </li>\n",
        "  <li> <b>parch</b>: Number of parents or children onboard </li>\n",
        "  <li> <b>ticket</b>: Ticket number </li>\n",
        "  <li> <b>fare</b>: Passenger fare </li>\n",
        "  <li> <b>cabin</b>: Cabin number </li>\n",
        "  <li> <b>embarked</b>: Port of embarkation (C = Cherbourg; Q = Queenstown; S = Southampton) </li>\n",
        "  <li> <b>boat</b>: Lifeboat (if the passenger survived, otherwise the value is Not a Number (NaN) </li>\n",
        "  <li> <b>body</b>: Body number (if the passenger did not survive and his body was found, otherwise the value is NaN) </li>\n",
        "  <li> <b>home.dest</b>: the passenger's destination </li>\n",
        " </ol>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2ed5fozqjce"
      },
      "source": [
        "## Data pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__vcZhPnavlg"
      },
      "source": [
        "### Feature selection\n",
        "Some features are not relevant to the task, for example:\n",
        "<ol>\n",
        "  <li> <b>name</b>: Name </li>\n",
        "  <li> <b>ticket</b>: Ticket number </li>\n",
        "  <li> <b>cabin</b>: Cabin number </li>\n",
        "  <li> <b>home.dest</b>: Passenger's destination </li>\n",
        " </ol>\n",
        " \n",
        "Other features are directly related to the passenger survival and are not interesting for our study because they give away the label to be predicted:\n",
        "<ol>\n",
        "  <li> <b>boat</b>: Lifeboat (if the passenger survived) </li>\n",
        "  <li> <b>body</b>: Body number (if the passenger did not survive and his body was found) </li>\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoD8x0dXofmj"
      },
      "source": [
        "titanic_df.drop(['name', 'ticket', 'cabin', 'home.dest', 'boat', 'body'], axis=1, inplace=True)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PW_IWwqwdHq"
      },
      "source": [
        "### Handling missing values\n",
        "\n",
        "Handling missing values in datasets is difficult since examples with missing values can be informative for subgroups. Suppose that features associated with third-class tickets have many missing values compared to first-class tickets. Removing all examples with missing values will introduce a bias in the dataset and could completely change the correlations between features and the probability of survival. Another approach is to impute missing values by replacing them with simples statistics such as the mean or the median of the feature. Other imputing techniques use the other features to predict the missing values, which is very close to a ML task. See Scikit-learn reference for more details ([Imputation of missing values](https://www.google.com/url?q=https://scikit-learn.org/stable/modules/impute.html&sa=D&source=editors&ust=1617044175668000&usg=AFQjCNHxRm4BcLBrZEPzW7i3C_PJ7oAuPQ)). Thus, handling missing values should be done carefully and often depend on the dataset and domain knowledge. In the following, we discard all examples with missing values, but since it is a substantial number of examples, we are probably introducing a bias in the dataset. To avoid such bias, one can re-annotate the data manually."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8YKDg69wjb_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be5a3b17-2a17-4ac8-e028-b29ce17f0200"
      },
      "source": [
        "n_examples = len(titanic_df)\n",
        "titanic_df = titanic_df.dropna(axis=0, how='any').reset_index(drop=True)\n",
        "print(f'We removed {n_examples-len(titanic_df)} examples over {n_examples} containing missing values.')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "We removed 266 examples over 1309 containing missing values.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MckYm0M_xhR"
      },
      "source": [
        "### Feature encoding\n",
        " \n",
        "Some features are **categorical variables**, which means that they can take a finite number of values.\n",
        " <ol>\n",
        "  <li> <b>pclass</b>: Passenger Class </li>\n",
        "  <li> <b>sex</b>: Sex </li>\n",
        "  <li> <b>embarked</b>: Port of embarkation </li>\n",
        " </ol>\n",
        "\n",
        "To process categorical variables, we need to encode them in a way that does not imply an arbitrary order such as using natural numbers (e.g., 1, 2, 3). <a href=\"https://en.wikipedia.org/wiki/One-hot#Machine_learning_and_statistics\">One-hot encoding</a> is a way to achieve it. To use this encoding, we can simply call the function `get_dummies` in Pandas. The meaning of the encoded variables is as follows:\n",
        "\n",
        "<ol>\n",
        "  <li> <b>survived</b>: Survived? (0 = no; 1 = yes) </li>\n",
        "  <li> <b>pclass_1</b>: (1 if passenger in first class; 0 if not) </li>\n",
        "  <li> <b>pclass_2</b>: (1 if passenger in second class; 0 if not) </li>\n",
        "  <li> <b>pclass_3</b>: (1 if passenger in third class; 0 if not) </li>\n",
        "  <li> <b>sex_female</b>: (1 if passenger is female; 0 if not) </li>\n",
        "  <li> <b>sex_male</b>: (1 if passenger is male; 0 if not) </li>\n",
        "  <li> <b>age</b>: Age </li>\n",
        "  <li> <b>sibsp</b>: Number of brothers, sisters, or spouses onboard </li>\n",
        "  <li> <b>parch</b>: Number of parents or children onboard </li>\n",
        "  <li> <b>fare</b>: Passenger fare </li>\n",
        "  <li> <b>embarked_C</b>: (1 if Port of embarkation = Cherbourg (C); 0 otherwise) </li> \n",
        "  <li> <b>embarked_Q</b>: (1 if Port of embarkation = Queenstown (Q); 0 otherwise) </li> \n",
        "  <li> <b>embarked_S</b>: (1 if Port of embarkation = Southampton (S); 0 otherwise)</li> \n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7bFJc5X_qjx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "2a2bcd6f-1a0e-4df2-ff74-2e8e555db701"
      },
      "source": [
        "titanic_preprocess_df = pd.get_dummies(data=titanic_df, columns=['pclass', 'sex', 'embarked'])\n",
        "titanic_preprocess_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>embarked_C</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>29.0000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>211.3375</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>2.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>30.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>25.0000</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>151.5500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   survived      age  sibsp  ...  embarked_C  embarked_Q  embarked_S\n",
              "0         1  29.0000      0  ...           0           0           1\n",
              "1         1   0.9167      1  ...           0           0           1\n",
              "2         0   2.0000      1  ...           0           0           1\n",
              "3         0  30.0000      1  ...           0           0           1\n",
              "4         0  25.0000      1  ...           0           0           1\n",
              "\n",
              "[5 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeBNt5EW6tm9"
      },
      "source": [
        "Now, we can check if all examples have a one-hot encoding for their categorical variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RjZZEokvJ3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a2fc59d9-3a50-4fb3-e3d0-b8f638bf2ca7"
      },
      "source": [
        "titanic_preprocess_df.loc[titanic_preprocess_df[['sex_male','sex_female']].sum(axis=1) != 1]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>embarked_C</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [survived, age, sibsp, parch, fare, pclass_1, pclass_2, pclass_3, sex_female, sex_male, embarked_C, embarked_Q, embarked_S]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3yueVPfvEhI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "d49a00ad-c027-4388-aef9-5e9377c7090a"
      },
      "source": [
        "titanic_preprocess_df.loc[titanic_preprocess_df[['pclass_1','pclass_2', 'pclass_3']].sum(axis=1) != 1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>embarked_C</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [survived, age, sibsp, parch, fare, pclass_1, pclass_2, pclass_3, sex_female, sex_male, embarked_C, embarked_Q, embarked_S]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4No15nhu8Hi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "bddce238-46c8-4843-9bb0-ea2933efd71a"
      },
      "source": [
        "titanic_preprocess_df.loc[titanic_preprocess_df[['embarked_C','embarked_Q', 'embarked_S']].sum(axis=1) != 1]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>survived</th>\n",
              "      <th>age</th>\n",
              "      <th>sibsp</th>\n",
              "      <th>parch</th>\n",
              "      <th>fare</th>\n",
              "      <th>pclass_1</th>\n",
              "      <th>pclass_2</th>\n",
              "      <th>pclass_3</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>sex_male</th>\n",
              "      <th>embarked_C</th>\n",
              "      <th>embarked_Q</th>\n",
              "      <th>embarked_S</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [survived, age, sibsp, parch, fare, pclass_1, pclass_2, pclass_3, sex_female, sex_male, embarked_C, embarked_Q, embarked_S]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4a-35Xa66Tj"
      },
      "source": [
        "Since there are only two examples with no port of embarkation, we decide to discard them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wODe7zbglC1I",
        "outputId": "f4d2a756-7f51-43c2-d607-0ea1b85602e3"
      },
      "source": [
        "titanic_df.loc[148,:]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pclass            1\n",
              "survived          0\n",
              "sex          female\n",
              "age              50\n",
              "sibsp             0\n",
              "parch             0\n",
              "fare        28.7125\n",
              "embarked          C\n",
              "Name: 148, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkBNPNPDk9ZN"
      },
      "source": [
        "# Drop rows where there is no port of embarkation associated\n",
        "titanic_preprocess_df = titanic_preprocess_df.drop(index=148).reset_index(drop=True)\n",
        "titanic_preprocess_df = titanic_preprocess_df.drop(index=248).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2p2GAKHm-92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eebabcad-e4aa-42a2-b8b9-ffecc0524942"
      },
      "source": [
        "print(f'There are {len(titanic_preprocess_df)} remaining examples in the dataset.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1043 remaining examples in the dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJcs6PUTavlm"
      },
      "source": [
        "## Train / validation / test split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjbgvffmavlo"
      },
      "source": [
        "At this point, we need to divide the dataset into three subsets:\n",
        "\n",
        "<ol>\n",
        "<li> <b> Train</b> (60% of the dataset): used to train the classification model. </li>   \n",
        "<li> <b> Validation</b> (20% of the dataset): used to evaluate hyper-parameters on held-out data. </li>   \n",
        "<li> <b> Test</b> (20% of the dataset): used to evaluate the generalization performance of the chosen model on held-out data. </li>\n",
        "</ol>\n",
        "\n",
        "We use the <a href=\"https://numpy.org/doc/stable/reference/generated/numpy.split.html\">numpy.split function</a> to separate our dataset into subsets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs07L8F5488f"
      },
      "source": [
        "### Exercise 1\n",
        "Complete the missing code to create the validation and the test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBmL8VBOavlo"
      },
      "source": [
        "train, validate, test = np.split(\n",
        "    titanic_preprocess_df.sample(frac=1, random_state=seed), # cela revient a un shuffle du set de donnees\n",
        "    [int(.6*len(titanic_preprocess_df)), int(.8*len(titanic_preprocess_df))])\n",
        "\n",
        "# Remove the label column from X and create a label vectors.\n",
        "X_train = train.drop(['survived'], axis=1).to_numpy()\n",
        "y_train = train['survived'].to_numpy()\n",
        "\n",
        "X_val = validate.drop(['survived'], axis=1).to_numpy() \n",
        "y_val = validate['survived'].to_numpy()\n",
        "\n",
        "X_test = test.drop(['survived'], axis=1).to_numpy() \n",
        "y_test = test['survived'].to_numpy()\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wv74TbIWavlr"
      },
      "source": [
        "## Datasets in PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_LJtG-Xavlt"
      },
      "source": [
        "We will use the subclass <b><a href=\"https://pytorch.org/docs/master/data.html#torch.utils.data.TensorDataset\"> `torch.utils.data.TensorDataset`</a> </b> to manipulate together the features and targets of a dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZUfbAtG5S92"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Complete the missing code to load the validation and the test sets in TensorDatasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JtT4tV7avlt"
      },
      "source": [
        "train_dataset = TensorDataset(torch.from_numpy(X_train).float(), torch.from_numpy(y_train).long())\n",
        "val_dataset = TensorDataset(torch.from_numpy(X_val).float(), torch.from_numpy(y_val).long())\n",
        "test_dataset = TensorDataset(torch.from_numpy(X_test).float(), torch.from_numpy(y_test).long())"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obEPHnlTavkc"
      },
      "source": [
        "# How to define the learning algorithm?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhN5GL6Gavks"
      },
      "source": [
        "To train a deep learning model, we need to define:\n",
        "* the network architecture by choosing the non-linear function and the number of hidden units per layer, \n",
        "* the loss function and optimizer.\n",
        "\n",
        "In this tutorial, we consider the multilayer perceptron (MLP). A MLP is a simple computational graph composed of \"hidden layers,\" which are defined by two modules: a **linear transformation** followed by a **non-linearity**. The result of a hidden layer is a vector called a **distributed representation** where each component is associated with a hidden unit.\n",
        "\n",
        "To solve our task, we will use a MLP with the following architecture:\n",
        "* the input dimension of the model is 12,\n",
        "* the output dimension of the model is 2,\n",
        "* the first dimension of the output is the probability of death and the second dimension is the probability of survival,\n",
        "* the number of hidden layers is 3, \n",
        "* the dimensions of the hidden layers are 20, 40, 20 respectively, \n",
        "* the activation function is a ReLu for all hidden layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "701t0e-ravkr"
      },
      "source": [
        "## How to define a model in PyTorch?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4F5cyijavkv"
      },
      "source": [
        "The <a href=\"https://pytorch.org/docs/stable/nn.html\">PyTorch NN package</a> contains many useful classes for creating computation graphs.\n",
        "* The class <a href=\"https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module\">torch.nn.Module</a>: \n",
        "any new module must inherit from this class or its descendants (subclasses).\n",
        "* The `forward` method:  any class defining a module must implement the `forward(...)` method, which defines the transformation of inputs to outputs.\n",
        "* The class <a href=\"https://pytorch.org/docs/master/generated/torch.nn.Linear.html#torch.nn.Linear\">`torch.nn.Linear(in_features, out_features)`</a>: this class implements a linear transformation. By default, it takes two parameters: \n",
        "    * `in_features`: the size of the data at the input of the module. \n",
        "    * `out_features`: the size of the data at the output of the module.\n",
        "\n",
        "* The module <a href=\"https://pytorch.org/docs/master/nn.functional.html#torch-nn-functional\">`torch.nn.functional`</a>: \n",
        "it defines a set of functions that can be applied directly to any tensor. As examples, we have:\n",
        "    * non-linear functions: `sigmoid(...)`, `tanh(...)`, `relu(...)`, ...\n",
        "    * loss functions: `mse_loss(...)`, `nll(...)`, `cross_entropy(...)`, ... \n",
        "    * regularization functions: `droupout(...)`, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tscha6S-KIBB"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Complete the following methods to define a neural network:\n",
        "* The `__init__` method that defines the layers.\n",
        "* The `forward(input)` method that returns the `output`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR5eBfIbavk0"
      },
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self):\n",
        "      super(NeuralNet, self).__init__()\n",
        "      self.layer1 = nn.Linear(12, 20)\n",
        "      self.layer2 = nn.Linear(20, 40)\n",
        "      self.layer3 = nn.Linear(40, 20)\n",
        "      self.output = nn.Linear(20, 2)\n",
        "\n",
        "    def forward(self, x):      \n",
        "      x = F.relu(self.layer1(x))\n",
        "      x = F.relu(self.layer2(x))\n",
        "      x = F.relu(self.layer3(x))\n",
        "      out = torch.sigmoid(self.output(x))\n",
        "      return out"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvLnHRZ5avk2"
      },
      "source": [
        "## Making predictions with a neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEXgJMDDavk3"
      },
      "source": [
        "Now, we are ready to test our neural network on randomly selected data.\n",
        "\n",
        "In PyTorch, a model has two different modes:\n",
        "    <ul>\n",
        "    <li> <b>train</b>: used during training, </li>\n",
        "    <li> <b>eval</b>: used during inference for model evaluation. </li>\n",
        "    </ul>\n",
        "\n",
        "The distinction is important since some modules behave differently according to this mode.\n",
        "We will use the <b>eval</b> mode in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqtE_hr650pz"
      },
      "source": [
        "### Exercise 4\n",
        "Complete the missing code so that the model outputs a probability vector. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzcABMezavk6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50598e77-27f7-4c71-9cd1-bcf93e1bd089"
      },
      "source": [
        "# Model definition\n",
        "neural_net = NeuralNet()\n",
        "neural_net = neural_net.to(device)\n",
        "\n",
        "# Evaluation mode activation\n",
        "neural_net = neural_net.eval()\n",
        "\n",
        "# Select the first 5 data points\n",
        "data, target = val_dataset[0:5]\n",
        "data = data.to(device)\n",
        "target = target.to(device)\n",
        "\n",
        "# Forward propagation of the data through the model\n",
        "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "\n",
        "# Convert the logits into probabilities with softmax function\n",
        "output_proba = F.softmax(output,dim=1)\n",
        "\n",
        "# Printing the probability\n",
        "print(output_proba)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.5283, 0.4717],\n",
            "        [0.5202, 0.4798],\n",
            "        [0.5072, 0.4928],\n",
            "        [0.5104, 0.4896],\n",
            "        [0.5569, 0.4431]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVep0BElavlS"
      },
      "source": [
        "The rows define the output of the network, in terms of probabilities over two classes: <b>deceased</b> (first column) or <b>survived</b> (second column), for each of the five input data points. Let us take the label with maximum probability as the predicted label and compare it to the correct label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jV4No36qjdU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "715af3cc-a85d-4361-83cb-9a8848a50d80"
      },
      "source": [
        "# Printing predictions (class with the highest probability)\n",
        "_, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "print('Model prediction')\n",
        "print(prediction)\n",
        "\n",
        "# Printing the real labels\n",
        "print(\"Actual data\")\n",
        "print(target)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model prediction\n",
            "tensor([0, 0, 0, 0, 0], device='cuda:0')\n",
            "Actual data\n",
            "tensor([0, 0, 0, 0, 0], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEIIjqOuqjdc"
      },
      "source": [
        "### Exercise 5\n",
        "\n",
        "1.   What would be a good way to measure the model performances?\n",
        "2.   How does our model perform?\n",
        "3.   Considering that the model is not trained on the dataset, do you see any problem with your selected measure?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Fa66z1qqH9em"
      },
      "source": [
        "#@title Métriques\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the accuracy score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     Accuracy score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.accuracy_score(y_true, y_pred)\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Compute the F1 score.\n",
        "  \n",
        "  Args:\n",
        "     y_true: ground truth labels.\n",
        "     y_pred: predicted labels by a classifier.\n",
        "     \n",
        "  Return:\n",
        "     F1 score.\n",
        "     \n",
        "  \"\"\"\n",
        "  return metrics.f1_score(y_true, y_pred, average='macro')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reJFVgMHABD7",
        "outputId": "032b8dfc-4cab-4a47-834d-8df5eab04565"
      },
      "source": [
        "# calcul F1 score\n",
        "F1_score = f1_score(target.cpu().numpy(), prediction.cpu().numpy())\n",
        "print(f'F1 score is {F1_score:.2%}'.format(F1_score))"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score is 100.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0uySA2TCavmD"
      },
      "source": [
        "## Define the loss function and optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkoobCLMavmE"
      },
      "source": [
        "### Loss function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkX7uSXQavmF"
      },
      "source": [
        "We define the loss function according to the task we want to achieve.\n",
        "\n",
        "PyTorch offers <a href=\"https://pytorch.org/docs/stable/nn.html#loss-functions\">many ready-to-use loss functions</a>.\n",
        "\n",
        "For classification problems, the usual loss function is <b>cross-entropy</b>, and this is the one we will use in this tutorial. In PyTorch, it is defined by the function <a href=\"https://pytorch.org/docs/master/nn.functional.html#cross-entropy\">`torch.nn.functional.cross_entropy`</a>.  Cross entropy allows comparing a $p$ distribution with a reference distribution $t$. It attains its minimum when $t=p$. Its formula for calculating it between the prediction and the target is: $-\\sum_j t_{ij} \\log(p_{ij})$ where $p$ is the prediction, $t$ the target, $i$ the example and $j$ the classe of the target."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHnfYeS5avmF"
      },
      "source": [
        "def loss_function(prediction, target):\n",
        "    loss = F.cross_entropy(prediction, target)\n",
        "    return loss"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsx_cv9Wqjdj"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hcZaIKtavmH"
      },
      "source": [
        "In Pytorch, thanks to the automatic differentiation mechanism <a href=\"http://pytorch.org/docs/master/notes/autograd.html\">Autograd</a>, it is possible to automatically calculate the gradient of the loss function and backpropagate it through the computational graph.\n",
        "\n",
        "To do this, we only have to call the method `backward()` on the variable returned by the loss function, e.g., with\n",
        "\n",
        "```python\n",
        "loss = loss_function(....)\n",
        "loss.backward()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YNo_ymYavmH"
      },
      "source": [
        "### Optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4AlX9TwavmH"
      },
      "source": [
        "PyTorch provides a <a href=\"http://pytorch.org/docs/master/optim.html#algorithms\">set of optimization methods (`torch.optim`)</a> commonly used by the deep learning community. These methods include the following: \n",
        "* <b>SGD</b> (Stochastic Gradient Descent) <a href=\"http://pytorch.org/docs/master/optim.html#torch.optim.SGD\">`torch.optim.SGD(net.parameters(), lr=learning_rate)`</a>\n",
        "* <b>Adam</b> (Adaptive Moment Estimation): a variant of the gradient descent method in which the learning rate is adjusted for each parameter by estimating the first and second moments of the gradients. This optimizer has demonstrated excellent performance compared to SGD on many benchmarks.\n",
        "\n",
        "To be able to use an optimizer in PyTorch, we must instantiate it by passing the following elements:\n",
        "* <b>The parameters of the model</b>: these are obtained using the method `parameters()` on the instantiated model.\n",
        "* <b>The learning rate (lr)</b>: this is the learning rate to be used to update parameters during the optimization process. \n",
        "* There may be other parameters specific to the chosen optimizer.\n",
        "\n",
        "PyTorch offers a simplified interface to interact with any optimizer:\n",
        "* `zero_grad()`: Allows to reinitialize the gradients to zero at the beginning of an optimization step.\n",
        "* `step()`: Allows to perform an optimization step after a gradient backpropagation step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZ-lKExqavmI"
      },
      "source": [
        "We will use Adam with a lr of 0.001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDMOziJTavmI"
      },
      "source": [
        "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) "
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnFOAfdGqjdr"
      },
      "source": [
        "# How to train and evaluate a model?\n",
        "First, we need some definitions:\n",
        "<ol>\n",
        "<li>\n",
        "<b>Epoch</b>: a complete pass over the entire training dataset.\n",
        "</li>\n",
        "<li>\n",
        "<b>Iteration</b>: an update of the model parameters. Many iterations can occur before the end of an epoch.\n",
        "</li>\n",
        "<li>\n",
        "<b>Mini-batch</b>: A subset of training data used to estimate the average of gradients. In other words, at each iteration, a mini-batch is used. \n",
        "</li>\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLXjNiDTavmK"
      },
      "source": [
        "## Creating the mini-batches\n",
        "PyTorch offers a utility called <b><a href=\"http://pytorch.org/docs/master/data.html\"> `torch.utils.data.DataLoader`</a></b> to load any dataset and automatically split it into mini-batches. During training, the data presented to the network should appear in a different order from one epoch to another. We will prepare the `DataLoader` for our three datasets (training, validation, and test)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGoQZSdqavmM"
      },
      "source": [
        "train_batch_size = 32  # number of data in a training batch.\n",
        "eval_batch_size = 32   # number of data in an batch.\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "val_loader   = torch.utils.data.DataLoader(val_dataset, batch_size=eval_batch_size, shuffle=False)\n",
        "test_loader  = torch.utils.data.DataLoader(test_dataset, batch_size=eval_batch_size, shuffle=False)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4ecBllSdsQ_",
        "outputId": "b95dc20f-a690-4d07-a8fd-cebf2101efbb"
      },
      "source": [
        "train_loader_iter = iter(train_loader)\n",
        "\n",
        "for i in range(len(train_loader)):\n",
        "  t = next(train_loader_iter)\n",
        "  print(len(t[0])) "
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "32\n",
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ia3ai-GvavmP"
      },
      "source": [
        "## Simple training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9wNZrTnavmQ"
      },
      "source": [
        "Here we define our training procedure for an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyK9xCsZavmR"
      },
      "source": [
        "def train(epoch, model, train_loader, optimizer, device):\n",
        "    \n",
        "    # activate the training mode\n",
        "    model.train()\n",
        "    \n",
        "    torch.set_grad_enabled(True)\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    # iteration over the mini-batches\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        \n",
        "        # transfer the data on the chosen device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        # reinitialize the gradients to zero\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward propagation on the data\n",
        "        prediction = model(data)\n",
        "        \n",
        "        # compute the loss function w.r.t. the targets\n",
        "        loss = loss_function(prediction, target)\n",
        "        \n",
        "        # execute the backpropagation\n",
        "        loss.backward()\n",
        "        \n",
        "        # execute an optimization step\n",
        "        optimizer.step()\n",
        "        \n",
        "        # accumulate the loss\n",
        "        total_loss += loss.item()*len(data)\n",
        "        \n",
        "        # compute the number of correct predictions\n",
        "        _, pred_classes = torch.max(prediction, dim=1)        \n",
        "        correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()\n",
        "         \n",
        "        \n",
        "    # compute the average loss per epoch\n",
        "    mean_loss = total_loss/len(train_loader.dataset)\n",
        "    \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(train_loader.dataset)\n",
        "        \n",
        "    print('Train Epoch: {}   Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        epoch, mean_loss, correct, len(train_loader.dataset),\n",
        "        100. * acc))   \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGexbWaHavmU"
      },
      "source": [
        "## Evaluation procedure\n",
        "Here we define our model evaluation procedure.\n",
        "<br/>\n",
        "In addition to switching the model to **eval** mode, it is essential to disable the gradient calculation. \n",
        "<br/>\n",
        "To do this, PyTorch offers a set of context managers to <a href=\"https://pytorch.org/docs/0.4.0/torch.html#locally-disabling-gradient-computation\">locally disable/enable gradient calculation </a>:\n",
        "1. `torch.no_grad()`: disable gradient calculation.\n",
        "2. `torch.enable_grad()`: enable gradient calculation.\n",
        "3. `torch.set_grad_enabled(bool)`: enable/disable gradient calculation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gQj9W5LavmU"
      },
      "source": [
        "def evaluate(model, eval_loader, device):\n",
        "    \n",
        "    # activate the evaluation mode\n",
        "    model.eval()\n",
        "    \n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        # iterate over the batches\n",
        "        for batch_idx, (data, target) in enumerate(eval_loader):\n",
        "\n",
        "            # transfer the data on the chosen device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            # forward propagation on the data\n",
        "            prediction = model(data)\n",
        "\n",
        "            # compute the loss function w.r.t. the targets\n",
        "            loss = loss_function(prediction, target)           \n",
        "\n",
        "\n",
        "            # accumulate the loss\n",
        "            total_loss += loss.item()*len(data)\n",
        "\n",
        "            # compute the number of correct predictions en sortie)\n",
        "            _, pred_classes = torch.max(prediction, dim=1) \n",
        "            correct += pred_classes.eq(target.view_as(pred_classes)).sum().item()         \n",
        "          \n",
        "    \n",
        "    # compute the average loss per epoch\n",
        "    mean_loss = total_loss/len(eval_loader.dataset)\n",
        "    \n",
        "    # compute the accuracy\n",
        "    acc = correct / len(eval_loader.dataset)\n",
        "        \n",
        "    print('Eval:  Avg_Loss: {:.5f}   Acc: {}/{} ({:.3f}%)'.format(\n",
        "        mean_loss, correct, len(eval_loader.dataset),\n",
        "        100. * acc)) \n",
        "    \n",
        "    # return the average loss and the accuracy\n",
        "    return mean_loss, acc"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQLklQXAavmW"
      },
      "source": [
        "## Checkpointing\n",
        "\n",
        "During training, we recommend saving the model parameters periodically. By doing so, we avoid having to retrain the model from scratch if the experiment goes wrong such as losing communication with GPU, out-of-memory error, numerical errors, incorrect learning rates making the experiment unstable, etc. This practice is commonly referred to as <b>checkpointing</b>.\n",
        "\n",
        "PyTorch offers <a href=\"http://pytorch.org/docs/master/notes/serialization.html\">a simple mechanism</a> to perform this operation.\n",
        "\n",
        "We implement two methods here:\n",
        "<ul>\n",
        "<li> the first one for <b> saving </b> a model,</li>\n",
        "<li> the second for <b> loading </b> a model checkpoint. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMmNpma2avmX"
      },
      "source": [
        "def save_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # saving the model parameters\n",
        "    torch.save(model.state_dict(), filename)\n",
        "    \n",
        "    return model\n",
        "    "
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZptgqQRavmZ"
      },
      "source": [
        "def load_model(epoch, model, path='./'):\n",
        "    \n",
        "    # creating the file name indexed by the epoch value\n",
        "    filename = path + 'neural_network_{}.pt'.format(epoch)\n",
        "    \n",
        "    # loading the parameters of the saved model\n",
        "    model.load_state_dict(torch.load(filename))\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ve8sOocWavma"
      },
      "source": [
        "It is also possible to save the optimizer's status in PyTorch, which is very important when we want to resume training the model from a given backup. For more information, please consult <a href='https://discuss.pytorch.org/t/saving-and-loading-a-model-in-pytorch/2610/3'>the following URL</a>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lcAP8-1avma"
      },
      "source": [
        "## Putting everything together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keMpyePsavmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f6d056-0a84-46b3-bc74-8cf149379409"
      },
      "source": [
        "# maximum number of epoch\n",
        "numEpochs = 200\n",
        "\n",
        "# Saving frequency\n",
        "checkpoint_freq = 10\n",
        "\n",
        "# Directory for data backup\n",
        "path = './'\n",
        "\n",
        "# Accumulators of average losses obtained per epoch\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "# Performance accumulators per epoch\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Model definition\n",
        "neural_net = NeuralNet()\n",
        "\n",
        "# Load the model on the chosen device\n",
        "neural_net = neural_net.to(device)\n",
        "\n",
        "# Optimizer definition\n",
        "optimizer = optim.Adam(neural_net.parameters(), lr=0.001) \n",
        "# optimizer = optim.SGD(neural_net.parameters(), lr=0.001) \n",
        "\n",
        "\n",
        "# Learning loop\n",
        "for epoch in range(1, numEpochs + 1):\n",
        "    \n",
        "    # train the model with the train dataset\n",
        "    train_loss, train_acc = train(epoch, neural_net, train_loader, optimizer, device)   \n",
        "    \n",
        "    # evaluate the model with the validation dataset\n",
        "    val_loss, val_acc = evaluate(neural_net, val_loader, device)       \n",
        "    \n",
        "    # Save the losses obtained\n",
        "    train_losses.append(train_loss)    \n",
        "    val_losses.append(val_loss)\n",
        "    \n",
        "    # Save the performances\n",
        "    train_accuracies.append(train_acc)    \n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    # Checkpoint\n",
        "    if epoch % checkpoint_freq ==0:\n",
        "        save_model(epoch, neural_net, path)\n",
        "\n",
        "# Save the model at the end of the training\n",
        "save_model(numEpochs, neural_net, path)\n",
        "    \n",
        "print(\"\\n\\n\\nOptimization ended.\\n\")    \n"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1   Avg_Loss: 0.67082   Acc: 388/625 (62.080%)\n",
            "Eval:  Avg_Loss: 0.65948   Acc: 132/209 (63.158%)\n",
            "Train Epoch: 2   Avg_Loss: 0.64396   Acc: 405/625 (64.800%)\n",
            "Eval:  Avg_Loss: 0.63975   Acc: 137/209 (65.550%)\n",
            "Train Epoch: 3   Avg_Loss: 0.62692   Acc: 411/625 (65.760%)\n",
            "Eval:  Avg_Loss: 0.62783   Acc: 140/209 (66.986%)\n",
            "Train Epoch: 4   Avg_Loss: 0.61689   Acc: 414/625 (66.240%)\n",
            "Eval:  Avg_Loss: 0.62034   Acc: 146/209 (69.856%)\n",
            "Train Epoch: 5   Avg_Loss: 0.61411   Acc: 421/625 (67.360%)\n",
            "Eval:  Avg_Loss: 0.61619   Acc: 145/209 (69.378%)\n",
            "Train Epoch: 6   Avg_Loss: 0.61117   Acc: 423/625 (67.680%)\n",
            "Eval:  Avg_Loss: 0.61553   Acc: 146/209 (69.856%)\n",
            "Train Epoch: 7   Avg_Loss: 0.60847   Acc: 424/625 (67.840%)\n",
            "Eval:  Avg_Loss: 0.61416   Acc: 146/209 (69.856%)\n",
            "Train Epoch: 8   Avg_Loss: 0.60578   Acc: 425/625 (68.000%)\n",
            "Eval:  Avg_Loss: 0.61301   Acc: 145/209 (69.378%)\n",
            "Train Epoch: 9   Avg_Loss: 0.60511   Acc: 426/625 (68.160%)\n",
            "Eval:  Avg_Loss: 0.61261   Acc: 147/209 (70.335%)\n",
            "Train Epoch: 10   Avg_Loss: 0.60175   Acc: 427/625 (68.320%)\n",
            "Eval:  Avg_Loss: 0.61064   Acc: 143/209 (68.421%)\n",
            "Train Epoch: 11   Avg_Loss: 0.59716   Acc: 428/625 (68.480%)\n",
            "Eval:  Avg_Loss: 0.60704   Acc: 145/209 (69.378%)\n",
            "Train Epoch: 12   Avg_Loss: 0.59154   Acc: 442/625 (70.720%)\n",
            "Eval:  Avg_Loss: 0.60349   Acc: 148/209 (70.813%)\n",
            "Train Epoch: 13   Avg_Loss: 0.58468   Acc: 454/625 (72.640%)\n",
            "Eval:  Avg_Loss: 0.59845   Acc: 147/209 (70.335%)\n",
            "Train Epoch: 14   Avg_Loss: 0.57666   Acc: 459/625 (73.440%)\n",
            "Eval:  Avg_Loss: 0.59252   Acc: 147/209 (70.335%)\n",
            "Train Epoch: 15   Avg_Loss: 0.56432   Acc: 464/625 (74.240%)\n",
            "Eval:  Avg_Loss: 0.58112   Acc: 147/209 (70.335%)\n",
            "Train Epoch: 16   Avg_Loss: 0.55277   Acc: 473/625 (75.680%)\n",
            "Eval:  Avg_Loss: 0.56946   Acc: 151/209 (72.249%)\n",
            "Train Epoch: 17   Avg_Loss: 0.54476   Acc: 482/625 (77.120%)\n",
            "Eval:  Avg_Loss: 0.56881   Acc: 153/209 (73.206%)\n",
            "Train Epoch: 18   Avg_Loss: 0.53911   Acc: 480/625 (76.800%)\n",
            "Eval:  Avg_Loss: 0.56962   Acc: 149/209 (71.292%)\n",
            "Train Epoch: 19   Avg_Loss: 0.53589   Acc: 483/625 (77.280%)\n",
            "Eval:  Avg_Loss: 0.54795   Acc: 160/209 (76.555%)\n",
            "Train Epoch: 20   Avg_Loss: 0.52196   Acc: 492/625 (78.720%)\n",
            "Eval:  Avg_Loss: 0.56058   Acc: 152/209 (72.727%)\n",
            "Train Epoch: 21   Avg_Loss: 0.52570   Acc: 490/625 (78.400%)\n",
            "Eval:  Avg_Loss: 0.54350   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 22   Avg_Loss: 0.51583   Acc: 495/625 (79.200%)\n",
            "Eval:  Avg_Loss: 0.55121   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 23   Avg_Loss: 0.53181   Acc: 483/625 (77.280%)\n",
            "Eval:  Avg_Loss: 0.55294   Acc: 153/209 (73.206%)\n",
            "Train Epoch: 24   Avg_Loss: 0.51902   Acc: 493/625 (78.880%)\n",
            "Eval:  Avg_Loss: 0.54583   Acc: 156/209 (74.641%)\n",
            "Train Epoch: 25   Avg_Loss: 0.50956   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.53638   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 26   Avg_Loss: 0.50632   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.54325   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 27   Avg_Loss: 0.50709   Acc: 503/625 (80.480%)\n",
            "Eval:  Avg_Loss: 0.53981   Acc: 158/209 (75.598%)\n",
            "Train Epoch: 28   Avg_Loss: 0.50498   Acc: 498/625 (79.680%)\n",
            "Eval:  Avg_Loss: 0.56484   Acc: 154/209 (73.684%)\n",
            "Train Epoch: 29   Avg_Loss: 0.53375   Acc: 478/625 (76.480%)\n",
            "Eval:  Avg_Loss: 0.53802   Acc: 158/209 (75.598%)\n",
            "Train Epoch: 30   Avg_Loss: 0.50322   Acc: 505/625 (80.800%)\n",
            "Eval:  Avg_Loss: 0.52806   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 31   Avg_Loss: 0.50104   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52913   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 32   Avg_Loss: 0.49983   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.52675   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 33   Avg_Loss: 0.50080   Acc: 504/625 (80.640%)\n",
            "Eval:  Avg_Loss: 0.53029   Acc: 160/209 (76.555%)\n",
            "Train Epoch: 34   Avg_Loss: 0.49508   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.52680   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 35   Avg_Loss: 0.49751   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52604   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 36   Avg_Loss: 0.49926   Acc: 503/625 (80.480%)\n",
            "Eval:  Avg_Loss: 0.52743   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 37   Avg_Loss: 0.49911   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.53023   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 38   Avg_Loss: 0.49397   Acc: 508/625 (81.280%)\n",
            "Eval:  Avg_Loss: 0.53806   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 39   Avg_Loss: 0.49975   Acc: 499/625 (79.840%)\n",
            "Eval:  Avg_Loss: 0.53242   Acc: 160/209 (76.555%)\n",
            "Train Epoch: 40   Avg_Loss: 0.49963   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.52475   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 41   Avg_Loss: 0.49473   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52594   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 42   Avg_Loss: 0.49913   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52429   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 43   Avg_Loss: 0.49256   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.52915   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 44   Avg_Loss: 0.49956   Acc: 503/625 (80.480%)\n",
            "Eval:  Avg_Loss: 0.52194   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 45   Avg_Loss: 0.48967   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.52521   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 46   Avg_Loss: 0.50299   Acc: 498/625 (79.680%)\n",
            "Eval:  Avg_Loss: 0.53484   Acc: 157/209 (75.120%)\n",
            "Train Epoch: 47   Avg_Loss: 0.49683   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.52107   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 48   Avg_Loss: 0.49170   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.52441   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 49   Avg_Loss: 0.48708   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51964   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 50   Avg_Loss: 0.49152   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.51913   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 51   Avg_Loss: 0.49811   Acc: 504/625 (80.640%)\n",
            "Eval:  Avg_Loss: 0.52095   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 52   Avg_Loss: 0.48719   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.51961   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 53   Avg_Loss: 0.48644   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.52067   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 54   Avg_Loss: 0.48823   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51900   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 55   Avg_Loss: 0.49121   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.51898   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 56   Avg_Loss: 0.48756   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51715   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 57   Avg_Loss: 0.48592   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51940   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 58   Avg_Loss: 0.48965   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51744   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 59   Avg_Loss: 0.51372   Acc: 484/625 (77.440%)\n",
            "Eval:  Avg_Loss: 0.51714   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 60   Avg_Loss: 0.49010   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.51885   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 61   Avg_Loss: 0.48721   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.52821   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 62   Avg_Loss: 0.48779   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51602   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 63   Avg_Loss: 0.49138   Acc: 506/625 (80.960%)\n",
            "Eval:  Avg_Loss: 0.51861   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 64   Avg_Loss: 0.50119   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.51257   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 65   Avg_Loss: 0.48848   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.52092   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 66   Avg_Loss: 0.48953   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.51987   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 67   Avg_Loss: 0.49093   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.51716   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 68   Avg_Loss: 0.49838   Acc: 501/625 (80.160%)\n",
            "Eval:  Avg_Loss: 0.51215   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 69   Avg_Loss: 0.49166   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52389   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 70   Avg_Loss: 0.48424   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.52156   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 71   Avg_Loss: 0.48635   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.51910   Acc: 161/209 (77.033%)\n",
            "Train Epoch: 72   Avg_Loss: 0.48348   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51750   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 73   Avg_Loss: 0.48457   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.52471   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 74   Avg_Loss: 0.48802   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.51357   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 75   Avg_Loss: 0.48667   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51414   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 76   Avg_Loss: 0.48401   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.52812   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 77   Avg_Loss: 0.49988   Acc: 500/625 (80.000%)\n",
            "Eval:  Avg_Loss: 0.52275   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 78   Avg_Loss: 0.49639   Acc: 499/625 (79.840%)\n",
            "Eval:  Avg_Loss: 0.51456   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 79   Avg_Loss: 0.48198   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51527   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 80   Avg_Loss: 0.48375   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51892   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 81   Avg_Loss: 0.48262   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51801   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 82   Avg_Loss: 0.48312   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.53794   Acc: 157/209 (75.120%)\n",
            "Train Epoch: 83   Avg_Loss: 0.49427   Acc: 508/625 (81.280%)\n",
            "Eval:  Avg_Loss: 0.51388   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 84   Avg_Loss: 0.48098   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51643   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 85   Avg_Loss: 0.48231   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.52655   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 86   Avg_Loss: 0.48985   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.51358   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 87   Avg_Loss: 0.48576   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51329   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 88   Avg_Loss: 0.48256   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.51909   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 89   Avg_Loss: 0.48241   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51173   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 90   Avg_Loss: 0.47888   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.51904   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 91   Avg_Loss: 0.48125   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51648   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 92   Avg_Loss: 0.47985   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51881   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 93   Avg_Loss: 0.48478   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.50974   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 94   Avg_Loss: 0.48138   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52678   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 95   Avg_Loss: 0.48711   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.50630   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 96   Avg_Loss: 0.48024   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51362   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 97   Avg_Loss: 0.48235   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51224   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 98   Avg_Loss: 0.48052   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.52680   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 99   Avg_Loss: 0.48539   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51016   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 100   Avg_Loss: 0.48197   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.50982   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 101   Avg_Loss: 0.48380   Acc: 513/625 (82.080%)\n",
            "Eval:  Avg_Loss: 0.51803   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 102   Avg_Loss: 0.47722   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51839   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 103   Avg_Loss: 0.47608   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51967   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 104   Avg_Loss: 0.48089   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.50949   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 105   Avg_Loss: 0.47478   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.52053   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 106   Avg_Loss: 0.47504   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51798   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 107   Avg_Loss: 0.49257   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.53227   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 108   Avg_Loss: 0.49134   Acc: 507/625 (81.120%)\n",
            "Eval:  Avg_Loss: 0.52122   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 109   Avg_Loss: 0.49198   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.50722   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 110   Avg_Loss: 0.47556   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51796   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 111   Avg_Loss: 0.47468   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51504   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 112   Avg_Loss: 0.48897   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.52194   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 113   Avg_Loss: 0.48241   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52024   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 114   Avg_Loss: 0.48075   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51300   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 115   Avg_Loss: 0.47599   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51951   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 116   Avg_Loss: 0.47552   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.51036   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 117   Avg_Loss: 0.47699   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.52093   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 118   Avg_Loss: 0.47660   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.51341   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 119   Avg_Loss: 0.47763   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.52250   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 120   Avg_Loss: 0.48540   Acc: 510/625 (81.600%)\n",
            "Eval:  Avg_Loss: 0.51807   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 121   Avg_Loss: 0.48322   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51710   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 122   Avg_Loss: 0.47433   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.51318   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 123   Avg_Loss: 0.47652   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.50993   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 124   Avg_Loss: 0.47682   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51490   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 125   Avg_Loss: 0.47697   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.53510   Acc: 159/209 (76.077%)\n",
            "Train Epoch: 126   Avg_Loss: 0.48027   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52686   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 127   Avg_Loss: 0.47865   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51731   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 128   Avg_Loss: 0.47491   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51728   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 129   Avg_Loss: 0.47373   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.52455   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 130   Avg_Loss: 0.48852   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.53463   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 131   Avg_Loss: 0.49258   Acc: 511/625 (81.760%)\n",
            "Eval:  Avg_Loss: 0.51593   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 132   Avg_Loss: 0.47481   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51792   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 133   Avg_Loss: 0.47555   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.52013   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 134   Avg_Loss: 0.47993   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.51885   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 135   Avg_Loss: 0.48632   Acc: 512/625 (81.920%)\n",
            "Eval:  Avg_Loss: 0.52059   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 136   Avg_Loss: 0.48163   Acc: 515/625 (82.400%)\n",
            "Eval:  Avg_Loss: 0.51662   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 137   Avg_Loss: 0.47337   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52181   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 138   Avg_Loss: 0.47533   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.52060   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 139   Avg_Loss: 0.47559   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51585   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 140   Avg_Loss: 0.47653   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.52014   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 141   Avg_Loss: 0.47645   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51331   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 142   Avg_Loss: 0.47895   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51512   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 143   Avg_Loss: 0.47196   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.52551   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 144   Avg_Loss: 0.47802   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.52230   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 145   Avg_Loss: 0.47800   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.51457   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 146   Avg_Loss: 0.47928   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52156   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 147   Avg_Loss: 0.47940   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.52344   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 148   Avg_Loss: 0.47476   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.52081   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 149   Avg_Loss: 0.47768   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52029   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 150   Avg_Loss: 0.47325   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.52028   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 151   Avg_Loss: 0.48211   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51093   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 152   Avg_Loss: 0.47208   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51957   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 153   Avg_Loss: 0.47983   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.52901   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 154   Avg_Loss: 0.47418   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51242   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 155   Avg_Loss: 0.46999   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.52073   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 156   Avg_Loss: 0.47155   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51545   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 157   Avg_Loss: 0.47747   Acc: 517/625 (82.720%)\n",
            "Eval:  Avg_Loss: 0.51411   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 158   Avg_Loss: 0.47236   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.52106   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 159   Avg_Loss: 0.47187   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.52597   Acc: 162/209 (77.512%)\n",
            "Train Epoch: 160   Avg_Loss: 0.47301   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51949   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 161   Avg_Loss: 0.47060   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52174   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 162   Avg_Loss: 0.46985   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51576   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 163   Avg_Loss: 0.47939   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.51692   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 164   Avg_Loss: 0.48026   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.52247   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 165   Avg_Loss: 0.46905   Acc: 529/625 (84.640%)\n",
            "Eval:  Avg_Loss: 0.52221   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 166   Avg_Loss: 0.49650   Acc: 504/625 (80.640%)\n",
            "Eval:  Avg_Loss: 0.50684   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 167   Avg_Loss: 0.47889   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51904   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 168   Avg_Loss: 0.46860   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51961   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 169   Avg_Loss: 0.48140   Acc: 514/625 (82.240%)\n",
            "Eval:  Avg_Loss: 0.51956   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 170   Avg_Loss: 0.49678   Acc: 502/625 (80.320%)\n",
            "Eval:  Avg_Loss: 0.51260   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 171   Avg_Loss: 0.47860   Acc: 518/625 (82.880%)\n",
            "Eval:  Avg_Loss: 0.51652   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 172   Avg_Loss: 0.47252   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51524   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 173   Avg_Loss: 0.47304   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52131   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 174   Avg_Loss: 0.46812   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.52473   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 175   Avg_Loss: 0.47543   Acc: 519/625 (83.040%)\n",
            "Eval:  Avg_Loss: 0.51211   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 176   Avg_Loss: 0.46883   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.51822   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 177   Avg_Loss: 0.46939   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51390   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 178   Avg_Loss: 0.47106   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52254   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 179   Avg_Loss: 0.47964   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51578   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 180   Avg_Loss: 0.48869   Acc: 509/625 (81.440%)\n",
            "Eval:  Avg_Loss: 0.50821   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 181   Avg_Loss: 0.46992   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51949   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 182   Avg_Loss: 0.47587   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.52218   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 183   Avg_Loss: 0.47570   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51248   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 184   Avg_Loss: 0.47613   Acc: 520/625 (83.200%)\n",
            "Eval:  Avg_Loss: 0.53426   Acc: 163/209 (77.990%)\n",
            "Train Epoch: 185   Avg_Loss: 0.46988   Acc: 527/625 (84.320%)\n",
            "Eval:  Avg_Loss: 0.51749   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 186   Avg_Loss: 0.46880   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.51544   Acc: 168/209 (80.383%)\n",
            "Train Epoch: 187   Avg_Loss: 0.46990   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51858   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 188   Avg_Loss: 0.48200   Acc: 516/625 (82.560%)\n",
            "Eval:  Avg_Loss: 0.51105   Acc: 167/209 (79.904%)\n",
            "Train Epoch: 189   Avg_Loss: 0.47113   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.51828   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 190   Avg_Loss: 0.46965   Acc: 523/625 (83.680%)\n",
            "Eval:  Avg_Loss: 0.52149   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 191   Avg_Loss: 0.47084   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.51871   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 192   Avg_Loss: 0.46866   Acc: 527/625 (84.320%)\n",
            "Eval:  Avg_Loss: 0.51872   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 193   Avg_Loss: 0.47214   Acc: 521/625 (83.360%)\n",
            "Eval:  Avg_Loss: 0.51745   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 194   Avg_Loss: 0.46702   Acc: 526/625 (84.160%)\n",
            "Eval:  Avg_Loss: 0.52334   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 195   Avg_Loss: 0.47045   Acc: 524/625 (83.840%)\n",
            "Eval:  Avg_Loss: 0.52306   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 196   Avg_Loss: 0.47521   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52225   Acc: 164/209 (78.469%)\n",
            "Train Epoch: 197   Avg_Loss: 0.47189   Acc: 525/625 (84.000%)\n",
            "Eval:  Avg_Loss: 0.51137   Acc: 166/209 (79.426%)\n",
            "Train Epoch: 198   Avg_Loss: 0.47369   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.51983   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 199   Avg_Loss: 0.47483   Acc: 522/625 (83.520%)\n",
            "Eval:  Avg_Loss: 0.52256   Acc: 165/209 (78.947%)\n",
            "Train Epoch: 200   Avg_Loss: 0.46616   Acc: 527/625 (84.320%)\n",
            "Eval:  Avg_Loss: 0.52163   Acc: 165/209 (78.947%)\n",
            "\n",
            "\n",
            "\n",
            "Optimization ended.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86OZRLrjavmd"
      },
      "source": [
        "## Interpreting the output of the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mklvQruYavme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98292ead-455a-4602-9480-acf9410cdbe3"
      },
      "source": [
        "# Activate the evaluation mode\n",
        "neural_net = neural_net.eval()\n",
        "\n",
        "# Select the first 10 data points of the validation set\n",
        "data, target = val_dataset[0:10]\n",
        "data = data.to(device)\n",
        "\n",
        "# Executing the neural network\n",
        "output = neural_net(data)   # equivalent to neural_net.forward(data)\n",
        "\n",
        "# Transform the output into a probability distribution with a softmax function\n",
        "output_proba = F.softmax(output, dim=1)\n",
        "\n",
        "# Print the probability\n",
        "print(output_proba)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.7310, 0.2690],\n",
            "        [0.6476, 0.3524],\n",
            "        [0.7141, 0.2859],\n",
            "        [0.7275, 0.2725],\n",
            "        [0.2689, 0.7311],\n",
            "        [0.7311, 0.2689],\n",
            "        [0.2690, 0.7310],\n",
            "        [0.7230, 0.2770],\n",
            "        [0.2705, 0.7295],\n",
            "        [0.7311, 0.2689]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvIEqKt0qjeT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53310314-d1a0-490e-dc26-e7cea7982d2e"
      },
      "source": [
        "# For each example, retrieve the class with the highest probability.\n",
        "dummy, prediction = torch.max(output_proba, dim=1)\n",
        "\n",
        "print(\"Model predictions\")\n",
        "print(prediction)\n",
        "print(dummy)\n",
        "print(\"Targets\")\n",
        "print(target)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model predictions\n",
            "tensor([0, 0, 0, 0, 1, 0, 1, 0, 1, 0], device='cuda:0')\n",
            "tensor([0.7310, 0.6476, 0.7141, 0.7275, 0.7311, 0.7311, 0.7310, 0.7230, 0.7295,\n",
            "        0.7311], device='cuda:0', grad_fn=<MaxBackward0>)\n",
            "Targets\n",
            "tensor([0, 0, 0, 0, 0, 1, 1, 0, 0, 0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn8s38SJio1W",
        "outputId": "d00ca1fe-78d7-4760-fe39-c4ca7e27a606"
      },
      "source": [
        "F1_score = f1_score(target.cpu().numpy(), prediction.cpu().numpy())\n",
        "print(f'F1 score is {F1_score:.2%}'.format(F1_score))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score is 60.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V11J3Jihavmy"
      },
      "source": [
        "## Visualizing of the learning curve"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9_9C_tXavmz"
      },
      "source": [
        "Learning curves allow detecting problems that may have occurred during learning, for example, unstable learning, underfitting, or overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNcbpl0tavm0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c410328a-308d-40bf-ab31-083168a0f0ff"
      },
      "source": [
        "x = list(range(len(train_losses)))\n",
        "ax = plt.subplot(111)\n",
        "plt.plot(x, train_losses, 'r', label=\"Train\")\n",
        "plt.plot(x, val_losses, 'g', label=\"Validation\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Cross-entropy loss')\n",
        "plt.grid()\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "leg.get_frame().set_alpha(0.99)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd3hUVf7/XyeVNNIbCSWFGloSIFRFBUFBsFDEBoqKusqiP3XF1bWturb9slhQsa6roNKUIkhVBCkJRaQESIAUEkgvkDpzfn/cmcukMgkZUjiv57nPzJzb3tPu+34+pwkpJQqFQqFQVMeuuQUoFAqFomWiDEKhUCgUtaIMQqFQKBS1ogxCoVAoFLWiDEKhUCgUteLQ3AKaCj8/P9mlS5dG73/u3Dnc3NyaTlAToXQ1jJaqC1quNqWrYbRUXdA4bQkJCdlSSv9aV0op28QSGxsrL4XNmzdf0v62QulqGC1Vl5QtV5vS1TBaqi4pG6cNiJd1XFdVikmhUCgUtaIMQqFQKBS1ogxCoVAoFLUiZBsZamPAgAEyPj6+StmBAwcoLy9vJkUKhULRsnBycqJPnz5VyoQQCVLKAbVt32ZaMdVGeXk5sbGxVm0rpUQIYWNFDUfpahgtVRe0XG1KV8Noqbrg4toSEhIadDyVYlIoFApFrSiDUCgUCkWttOkUk1VIqS0ALTRsVCgUiuZARRAARuMFk2hCcnJy6N+/P/379ycoKIiQkBD99cUqz+Pj45k9e3aTa1IoFNZxzTXXsG7duipl8+bN4+GHH651+5EjR2JuKHPjjTeSn59fY5sXX3yRt99+u97zrlixgkOHDumv//GPf7Bhw4aGym8SVARhQ3x9fdm3bx+g/TDc3d158skn9fWVlZU4ONT+FQwYMIABAwbQVlqZKRStjWnTprF48WLGjBmjly1evJg33njjovuuWbOm0eddsWIF48ePp1evXgC8/PLLjT7WpaIiiMucVpoxYwYPPfQQcXFxPP300+zatYshQ4YQHR3N0KFDSUxMBGDLli2MHz8e0MzlvvvuY+TIkYSHhzN//vzLqlmhuBKZNGkSq1ev1qP9kydPcvr0aRYtWsSAAQOIiorihRdeqHXfLl26kJ2dDcCrr75Kt27dGD58uP7/Bli4cCEDBw6kX79+3HbbbZw/f57t27fz448/8tRTT9G/f3+SkpKYMWMGS5YsAWDjxo1ER0fTp08f7rvvPsrKyvTzvfDCC8TGxtKnTx+OHDnSJJ/BlRNBzJkDprv5GjS2DqJ/f5g3r8FS0tLS2L59O/b29hQWFrJ161YcHBzYsGEDzz77LEuXLq2xz5EjR9i8eTNFRUV0796dhx9+GEdHxwafW6FojcxZO4d9mXX8fxtJ/6D+zBtb9//Xx8eHQYMG8dNPPzFx4kQWL17MlClTmDt3Lr6+vhgMBq677jr++OMP+vbtW+sxEhISWLx4Mfv27aOyspKYmBi96f2tt97KAw88AMBzzz3Hp59+ymOPPcaECRMYP348kyZNqnKs0tJSZsyYwcaNG+nWrRv33HMPCxYsYM6cOQD4+fmRkJDAggULePvtt/nkk08u+TNSEUQzMHnyZOzt7QEoKChg8uTJ9O7dm8cff5yDBw/Wus+4ceNwdnbGz8+PgIAAzpw5czklKxRXJOY0E2jppWnTpvHdd98RExNDdHQ0Bw8erFJfUJ2tW7dyyy234OrqSvv27ZkwYYK+7s8//2TEiBH06dOHr7/+us7/vpnExETCwsLo1q0bANOnT+fXX3/V1996660AxMbGcvLkyca+5SpcORFEfXf6lZXaYx31AU2N5XC8zz//PNdccw3Lly/n5MmTjBw5stZ9nJ2d9ef29vZUmjUrFFcA9d3p25KJEyfy+OOPs2fPHs6fP4+Pjw/vvPMOu3fvxtvbmxkzZlBaWtqoY8+YMYMVK1bQr18/vvjiC7Zs2XJJWs3XiKa8PqgIApq1eWtBQQEhISEAfPHFF82mQ6FQ1MTd3Z1rrrmG++67j2nTplFYWIibmxuenp6cOXOGn376qd79r7rqKlasWEFJSQlFRUWsXLlSX1dUVERwcDAVFRV8/fXXermHhwdFRUU1jtW9e3dOnjzJ8ePHAfjqq6+4+uqrm+id1o4yiGbm6aefZu7cuURHR6uoQKFogUybNo39+/czbdo0+vXrR3R0ND169OCOO+5g2LBh9e4bExPD1KlT6devHzfccAMDBw7U173yyivExcUxbNgwevTooZfffvvtvPXWW0RHR5OUlKSXt2vXjs8//5zJkyfTp08f7OzseOihh5r+DVvQpgfrS0hIsG4sJoNBG8PkMqWYGkJLHfdF6Wo4LVWb0tUwWqousG4spurXxPoG61MRhEKhUChq5Yo3CCklBiHNL5pXjEKhULQgrniDAJCmRaFQKBQXUAZhQrbMlKJCoVA0Gy2vVrYJcXJysmqCDKM0IgAhlF8qFIq2i5OTU8N2kFK2iSU2NlY2lt5vhcmbpyLlxo2NPoat2Lx5c3NLqBWlq+G0VG1KV8NoqbqkbJw2IF7WcV1Vt8yAv4sfWW5AQUFzS1EoFIoWgzIIwM/Nn2xXoJbx2xUKheJKxaYGIYQYK4RIFEIcF0I8U8c2U4QQh4QQB4UQ31iUG4QQ+0zLj7bU6d8+iCxXVAShUCgUFtiskloIYQ+8D4wG0oDdQogfpZSHLLbpCswFhkkp84QQARaHKJFS9reVPkv8vULIdYXKgty2XWuvUCgUDcCWEcQg4LiUMllKWQ4sBiZW2+YB4H0pZR6AlPKsDfXUiZ+75ku5hc1yeoVCoWiR2PKGOQRItXidBsRV26YbgBBiG2APvCilXGta104IEQ9UAv+SUq6ofgIhxIPAgwCBgYGNHi737FnNGA6dPMihSxxyt6kpLi6+5GGAbYHS1XBaqjalq2G0VF1gA211NW+61AWYBHxi8fpu4L1q26wClgOOQBiaoXiZ1oWYHsOBk0BEfee7lGauG5I2SF5EbrnnqkYfw1a01CZ1SlfDaanalK6G0VJ1Sdm6mrmmAx0tXoeayixJA36UUlZIKU8AR4GuAFLKdNNjMrAFiLaVUH83fwCyyvJsdQqFQqFoddjSIHYDXYUQYUIIJ+B2oHprpBXASAAhhB9ayilZCOEthHC2KB8G1D2v3yXi76oZRHZloa1OoVAoFK0Om9VBSCkrhRCPAuvQ6hc+k1IeFEK8jBbS/Ghad70Q4hBgAJ6SUuYIIYYCHwkhjGgm9i9p0fqpqfF19QUgSxbb6hQKhULR6rBpq04p5RpgTbWyf1g8l8ATpsVym+1AH1tqs8TJ3on2lQ5kcf5ynVKhUChaPKontQlvYzuy7UrVnBAKhUJhQhmECW/hRpaLhDxVUa1QKBSgDELHy6G9Nh5TZmZzS1EoFIoWgTIIE55O3tqIrsogFAqFAlAGoePlGsAZNzBknG5uKQqFQtEiUAZhIsCzC5X2kJaZ2NxSFAqFokWgDMJEoGcXAJKzjzWvEIVCoWghKIMw0cGlAwDJRSnNrEShUChaBsogTAS0C8DeCMllqpJaoVAoQBmEjr2wp3OFK8kyt7mlKBQKRYtAGYQF4XiT7HSuuWUoFApFi0AZhAXhToEku1eCwdDcUhQKhaLZUQZhQbh7R7LdoDA9ubmlKBQKRbOjDMKCcN9IAE6c2NPMShQKhaL5UQZhQXhwLwCS0/9sZiUKhULR/CiDsCC8szar6fGso82sRKFQKJofm04Y1Nrw7tyd0ALYK440txSFQqFodlQEYYmrK4Ny2rGr/ERzK1EoFIpmRxlENQbRgSTHInLO5zS3FIVCoWhWlEFUI85bmwp7d/quZlaiUCgUzYsyiGrEhg9DSNh1dHNzS1EoFIpmRRlENTx69qdXFuxK3trcUhQKhaJZUQZRnZ49GZQOO/P+xCiNza1GoVAomg1lENUJCeG6085ky2K2nlJRhEKhuHJRBlEdIbhF9KJ9pQOf7fusudUoFApFs6EMohZcu0Vx+3Fnvj/4PYVlhc0tR6FQKJoFZRC1ERPDfVvPUVJZwpM/P0l6YXpzK1IoFIrLjjKI2njgAQYZApme5scnez4h8t1Ilhxa0tyqFAqF4rKiDKI23N0Rr/+LLz7J5ljnd4gOimby95N5+ZeXMRjVZEIKheLKoEEGIYTwFkL0tZWYFsU990BMDBHP/5uNk1ZyZ587eWHLC1z1xVUs2L2A7PPZza1QoVAobMpFDUIIsUUI0V4I4QPsARYKIf5te2nNjJ0dzJsHaWm4/Od9vrrlK76Y+AWpBak8suYRRnw+QlVgKxSKNo01EYSnlLIQuBX4r5QyDhhlW1kthBEjYPJkeOMNRHo60/tP59ScU6y9cy3Hco5x9/K7VWc6hULRZrHGIByEEMHAFGCVjfW0PN54AwwGePZZAIQQjIkcw9vXv82PiT+yMnFlMwtUKBQK22CNQbwMrAOOSyl3CyHCgWO2ldWCCAuDJ56Ar76CXRdGeH100KN09uzM/+34v2YUp1AoFLbjogYhpfxeStlXSvmI6XWylPI220trQcydC4GBMGcOSAmAg50Ds+Nm88upX9iTsaeZBSoUCkXTY00l9ZumSmpHIcRGIUSWEOKuyyGuxeDhAa+9Br//Dt9+qxfPjJ6Ju5O7iiIUCkWbxJoU0/WmSurxwEkgEnjKlqJaJNOnQ3Q0PPUUrFsHRiOe7TyZGT2TxX8uVr2tFQpFm8OqSmrT4zjgeyllgQ31tFzs7eHDD6GiAsaOhUceAWB23GyM0sj7u99vZoEKhULRtFhjEKuEEEeAWGCjEMIfKLWtrBbKoEFw6hTMnAmffAInTxLuHc7NPW7mw/gPOVd+rrkVKhQKRZNhTSX1M8BQYICUsgI4B0y05uBCiLFCiEQhxHEhxDN1bDNFCHFICHFQCPGNRfl0IcQx0zLdurdzGXB2hhdf1DrSvf02ALMHzSavNI8fE39sXm0KhULRhFhTSe0I3AV8K4RYAswEcqzYzx54H7gB6AVME0L0qrZNV2AuMExKGQXMMZX7AC8AccAg4AUhhHcD3pdtCQ2Fu++GTz+FrCxGdB5BoFsgKxJXNLcyhUKhaDKsSTEtQEsvfWBaYkxlF2MQWt+JZCllObCYmpHHA8D7Uso8ACnlWVP5GGC9lDLXtG49MNaKc14+5syB0lJYsgQ7YcfE7hNZc2wNpZVXZvZNoVC0PawxiIFSyulSyk2m5V5goBX7hQCpFq/TTGWWdAO6CSG2CSF2CCHGNmDf5qVPH4iKgkWLALi5x80Ulxez6cSmZhamUCgUTYPDxTfBIISIkFImAZh6UjfVmNcOQFdgJBAK/CqE6GPtzkKIB4EHAQIDA9myZUujhRQXFzd4/85xcYR99hm/f/899r6euNq78sGmD3BNd220jqbQdTlQuhpOS9WmdDWMlqoLbKBNSlnvAlwHpABbgF/Q+kJcY8V+Q4B1Fq/nAnOrbfMhcK/F641o0ck04COL8o+AafWdLzY2Vl4KmzdvbvhOR49KCVK+/baUUsrJ302WIe+ESKPReElaLlnXZUDpajgtVZvS1TBaqi4pG6cNiJd1XFetacW0Ee0ufzbwGNBdSrnZCu/ZDXQVQoQJIZyA24HqzXxWoEUPCCH80FJOyWhjP11vmn/CG7jeVNay6NoVYmJg6VIARoePJr0onSPZR5pZmEKhUFw6daaYhBC31rEqUgiBlHJZfQeWUlYKIR5Fu7DbA59JKQ8KIV5Gc6wfuWAEh9DSVk9JKXNM538FzWQAXpZS5jbonV0uxo2DV1+F3FxGhWujoG9I3kBP/57NLEyhUCgujfrqIG6qZ50E6jUIACnlGmBNtbJ/WDyXwBOmpfq+nwGfXewczc7YsfDKK7BhA2FTphDhHcH65PU8FvdYcytTKBSKS6JOg5BaayXFxRg0CLy9Ye1amDKFUeGj+ObAN1QYKnC0d2xudQqFQtFoGjQntaIWHBxg9GjNIKRkdPhoisqL2H1698X3VSgUihaMMoimYOxYyMiAAwcY0GEAAAfPHmxmUQqFQnFpKINoCq69VnvcupXQ9qE42jmSlJfUvJoUCoXiErFmLKYEIcRfWtRYSC2NTp0gJAR++w17O3vCvMOUQSgUilaPNRHEVKADsFsIsVgIMUYIIWysq3UhBAwbBtu2ARDhHUFSrjIIhULRurGmo9xxKeXf0TqxfYPW9PSUEOIl06irCtAMIjUVUlOJ9IkkKS/J3AtcoVAoWiVW1UEIIfoC7wBvAUuByUAhoEamMzNsmPa4bRsR3hEUlhWSU3LRUdEVCoWixXLRwfqEEAlAPvAp8IyUssy0aqcQYpgtxbUq+vUDNzfNIGLGAHA89zh+rn7NLEyhUCgahzURxGQp5XVSym8szAEAKWVdw3FceTg4QFwc/P47Ed4RAKoeQqFQtGqsMYgCIcR8IcQeU4um/wghfG2urDUyYAAcOECYWwgCoVoyKRSKVo01BrEYyAJuAyaZnn9rS1GtlthYKC+nXWISIe1DlEEoFIpWjTUTBgVLKV+xeP1PIcRUWwlq1cTEaI8JCaqpq0KhaPVYE0H8LIS4XQhhZ1qm0BLnZmgJRESApyfs2aMZhIogFApFK8Yag3gArf9DuWlZDMwSQhQJIQptKa7VIQRER0NCApE+kWQWZ1JcXtzcqhQKhaJRWNNRzkNKaSeldDAtdqYyDyll+8shslURGwv79xPRvjMAyXnJzSxIoVAoGoe1HeUmCCHeNi3jbS2qVRMTA2VlRORrH62qh1AoFK0Vawbr+xfwV+CQafmrEOJ1WwtrtfTrB0BEShGAqodQKBStFmtaMd0I9JdSGgGEEF8Ce4G5thTWagkLA8Ar5Sw+Lj4qglAoFK0Wa+eD8LJ47mkLIW0GV1cIDobkZNWSSaFQtGqsiSBeA/YKITYDArgKeMamqlo74eGaQdwYwa70Xc2tRqFQKBpFvRGEEMIOMAKDgWVoI7kOkVKqntT1YTKISO9ITuWfosJQ0dyKFAqFosHUaxCmeoenpZQZUsofTUvmZdLWegkPh9RUItp3xiANnCo41dyKFAqFosFYUwexQQjxpBCioxDCx7zYXFlrJjwcpCSizBWAlYkrWZ+0ntuX3M7BswebWZxCoVBYhzV1EOZxl/5iUSaB8KaX00YwtWTqX+BCN99uPPHzE/qq2OBYogKimkuZQqFQWI01BtFTSllqWSCEaGcjPW2DcM07PU5l8ufDf7L62GoKSgt4cNWDapY5hULRarAmxbTdyjKFmeBgcHaG5GQc7R25ucfNTO8/HR8XH3LOK4NQKBStgzojCCFEEBACuAghotGauAK0B1wvg7bWi52dlmZKrjoOk6+LL7mluY06ZFllGUIInOydmkKhQqFQXJT6UkxjgBlAKPBvi/Ii4FkbamobmJq6WnIpEcSk7yfh5+rH5xM/bwp1CoVCcVHqNAgp5ZfAl0KI26SUSy+jprZBeDj89htIqQ0DDvi6+nI893ijDnc05yh5JXlNqVChUCjqxZpK6lVCiDuALpbbSylftpWoNkF4OBQWQl4e+Gitgn1dfNlV0rie1fml+Sq9pFAoLivWGMQPQAGQAJTZVk4bwtSSieRk3SDMKSYpJUKIenauipSS/NJ8nO2dbaFUoVAoasUagwiVUo61uZK2hqVBDBgAaBFEmaGMwrJC4j6J46WRLzG198Wn9y6tLKXcUE5+ab4tFSsUCkUVrGrmKoToY3MlbQ1TZznLimpfV18A9p/ZT2JOIjvTd1p1qLxSre6hqLwIg9HQtDoVCoWiDqyJIIYDM4QQJ9BSTAKQUsq+NlXW2nF3h4CAqgbhohlEwukEADKLrRvWyjJyKCovwqudVz1bKxQKRdNgjUHcYHMVbZVqTV19XLS6iIQMzSDOnDtj1WEsDaKgtEAZhEKhuCxcNMUkpTwFdASuNT0/b81+CmoYhDnFZDaIxkQQBWUFTShQoVAo6saaOalfAP7GhSlGHYH/2VJUmyE8HFJSoEKbD8KcYkrMTgQaaRClyiAUCsXlwZpI4BZgAnAOQEp5GvCwpag2Q1gYGAyQmgpcSDFJJAC5JbmUG8ovehgVQSgUiubAGoMol1JKtCG+EUK42VZSG8KyqSvg7OCMm6P28dkJ7aM/e+4sAHsz9vLsxmcxSmONw1j2oFYRhEKhuFxYYxDfCSE+AryEEA8AG4CF1hxcCDFWCJEohDguhKgxj7UQYoYQIksIsc+03G+xzmBR/qO1b6hF0bWr9nj4sF5krofoE6C1HM4szuRI9hFGfzWa1397nUNZh2ocRkUQCoWiObCmkvptYAnafNTdgX9IKd+92H5CCHvgfbRWUL2AaUKIXrVs+q2Usr9p+cSivMSifII1b6bF0aGD1tR17169yJxmGhw6GICMogwmLJpApbESgN9Tf69xmPzSfH0/1VlOoVBcLqxqjSSlXC+lfArYIqVcb+WxBwHHpZTJUspyYDEwsZE6WydCQEwMJCToReaKarNB7EjbwbHcY7x+3ev4ufrxe1otBlGWT5B7EM72zirFpFAoLhvW9IOw5GVglZXbhgCpFq/TgLhatrtNCHEVcBR4XEpp3qedECIeqAT+JaVcUX1HIcSDwIMAgYGBbNmyxUppNSkuLr6k/esizM+PTj//zNZ16zA6O2Mo1npCi3RtLKbFexcDYJ9pTzeXbmw8urGKjuLiYk6cPoEwClztXDl84rBNdDYUW31el0pL1QUtV5vS1TBaqi6wgTYppdULsLcB204CPrF4fTfwXrVtfAFn0/NZwCaLdSGmx3DgJBBR3/liY2PlpbB58+ZL2r9Oli6VEqTcuVNKKeVDKx+Sdi/ZyfLKcun1Ly/Ji0inV5xkWWWZfO3X1yQvInPO51TRNeDjAfLGr2+UXed3lbcvud02OhuIzT6vS6Sl6pKy5WpTuhpGS9UlZeO0AfGyjutqQzu8zWrAtuloHezMhJrKdKSUOVJK8wixnwCxFuvSTY/JwBYguoFaWwaxprdkSjPNjJnJO9e/g6O9I0HuQQD0D+qPk70TQzoOAbS0kyV5JXl4tfPCs52nSjEpFIrLhjUd5SYLIcz9HsYIIZYJIWKsOPZuoKsQIkwI4QTcDlRpjSSECLZ4OQE4bCr3FkI4m577AcOAms17WgOdOmnDfZsMYkCHAcwZPAeAQLdArSxYG+11YIeB2Am7GhXV+aX5eDl74ensqVoxKRSKy4Y1EcTzUsoiIcRw4FrgU2DBxXaSUlYCjwLr0C7830kpDwohXhZCmFslzRZCHBRC7Admo01xCtATiDeVb0arg2idBiGEFkVYVFSbMUcQA0MGAuDm5EZPv57sP7Nf30aa5oJQEYRCobjcWFNJbR5fehywUEq5WgjxT2sOLqVcA6ypVvYPi+dzuTCEh+U224G2M8T40KHwyiuQkwO+vnqxbhAdBuplUQFRxJ+OB+BU/inOlJ3BIA14u3irCEKhUFxWrIkg0k0d5aYCa0ypHzVYX0MYMwaMRtiwoUrxVZ2vYkjoEHr49dDLovyjOJF3gvMV5xn11Sie/uNpALzaeeHVzktFEAqF4rJhzYV+ClqaaIyUMh/wAZ6yqaq2xsCB4O0N69ZVKb61561sn7kdezt7vSzKPwqJZH3Seo7nHie1RGv169VOq4NQkwYpFIrLhTUGEQysllIeE0KMBCYDu2yqqq3h4ACjR8PataA13a2TqIAoABbu0UYzsReaeZjrIAAKywptKFahUCg0rDGIpYBBCBEJfIzWdPUbm6pqi4wZAxkZcOBAvZtFeEfgaOfIT8d/wtXRlUkhkwBtiA5PZ80gVD2EQqG4HFhjEEZTi6RbgXelNuRG8EX2UVRn7FitRdM39Xuro70j3f26Y5RG4kLiuKfzPXxw4wf0D+qvRxANrYcoqSghKTep0dLbGqoeR6GwDmsMokIIMQ24hwvDbDjaTlIbpUMHmDoV3n8fcnPr3TTKX0szDes4DFcHVx4e+DB2wk4fsC/7fHaDTv329rfpvaC3GugPOJF3At83fWsdFFGhUFTFGoO4FxgCvCqlPCGECAO+sq2sNsrf/w7FxTBvXr2b6QbRaViV8kifSACO5hxt0Gm3pW6jtLKUjckbG7RfW+R47nEM0sCx3GPNLUWhaPFYM9z3IeBJ4IAQojeQJqV8w+bK2iK9e8PNN8MHH9RbWX1zj5u5IfIGRnQaUaU8xCMEdyd3jmQfsfqUUkp9Duy1x9davZ/lJEVtiazzWUDbfX/WUlRWxIbkDRffUHFFY81QGyOBY2hzO3wAHDWNvqpoDMOGaR3mCurOg/cJ7MOaO9fg5lR18j4hBD18unM4+3Ade9YkpSCF7PPZONo5sjZprXkgxHpJOJ2A31t+/HHmD6vP01owp+fySq9sg/hi3xeM/mo0qQWpta5/ZPUj/H3j3y+zqrZHpbGSf/76T4rKippbSqOwJsX0DnC9lPJqKeVVwBjg/2wrqw3T0TR+YWrtf8x6OXSInj/v4XBG/S2hLDH3yr63/72kFaZZZS470nZglEb+PPtnwzW2cLLOqQgCIKM4A4A9GXtqXb/s8DI2nlApyUsl/nQ8z29+nlVHrZ0loWVhjUE4SikTzS+klEdRldSNpy6DqKy8uGkcP06PLElaSabVdyTxp+NxsHPgqWFa30Zr0kzmaU9TClKsOkdrwhxB5Je1vAr7N357g51pOy/LucyfQ20GkVeSx5lzZ/R0nKLx5JzPAbSphVsj1hhEghDiEyHESNOyEIi3tbA2S10G8eWX0K0b5Ndz4SoooKfpP5uYk1j3dhbEZ8TTJ6APkT6RhHuHsz11+0X3OZStGURd6YfWTHaJKcXUwiKIckM5czfO5eOEjy/L+cwGsTdzb4115t/W2XNnL4uWtkxOSds3iIfQhtqebVoOAQ/bUlSbJjgY7O1rGkRiIpSWQnJy3fsWFtLT1ML1cNaFVFFhWSGTvpvEwbMHq2xeaawk4XQCAzpcGE589+ndF5VoPk5KYduLIPQUUwurgzhddBqJvGytq+ozCHMjiOLyYkoqSi6LnrZKbonWpD3zXBs0CCGEPbBfSvlvKeWtpuX/LCb5UTQUBwetT0R1g8jQcsKcPFn3voWFROSCA3b8dPwn5qydQ3phOgsTFrL08FJe2K85+E4AACAASURBVPJClc0/2/sZeaV5jOs6DtAMIqUgpcad4UfxH+mpp6xzWXpqoU1GEOdbZgSRVpgGaM1wLwfm7zitMI388qpRq+XNR0tIMx3KOtRqc/jmFFNGUUYzK2kc9RqElNIAJAohOl0mPVcGHTvWNIjTp7XHU6fq3q+wEEcjROLDoj8X8Z+d/+HeH+5l/q752At7lh1epveYLiwr5PnNzzOi0wgmdNem3zDPO7E7/UIUUVhWyOy1s/nnr9oI7uZK7HDvcJvUQaQVpnHH0jsoLi9u8mOnFqSyIGkB5YbyOrdpqa2YzGacUZxhk8+mOtnns+nm2w2AY8VVo5YjOReaUbeENNOLW15kxooZzS2jUegRRBtOMXkDB4UQG4UQP5oXWwtr09RmEFZGEAD3lvXk9t638+LVL7I+eT0pBSl8MO4DHO0deW3ra5RWlnL/j/dz9txZ/j3m3wghAIgJjkEgqqSZVh1dRbmhnISMBMoN5XoF9diIseSV5jX5xeqHIz+w6M9F7Epv+vEelx9Zzndp39XZIdAojbVGEBWGCs6Vn2vw+Q5nHSa9ML1GeVJuEonZ1tURmTFHEGD7KMJgNJBbksuosFHa+Yqrnu9I9hFCPEKAlmEQf579k5ySHMoqW1/i4kqog3geGA+8jNbk1bwoGovZIIqKYI+pFYk5grDCIJ7O7sGi2xbx/NXPMyZiDNFB0dwfcz/3R9/PZ/s+I+CtAL4/9D1vjnpTr38AcHdyp6d/T3ak7eCD3R+wPXU7Sw8vBaC0spQ/zvzBoaxDuDu5M7TjUKDp00wHs7T6jRN5J5r0uHBBa13piILSAgzSgJ+rHyWVJfoF59mNzzLk0yENPt9t393G0xuerlH+8OqHufeHext0rNTCC5+zrQ0ivzQfozTSzbcbnTw7cfzchfOVG8pJyk3iqs5aVydznc2lUlxeTIWhosH7lRvK9XqZM+fO1LndqfxTvLntTav6+VxOzAaRfT67Ue+/uanTIIQQkUKIYVLKXywXtBnm0uraT2EFHTtCWRlMnw5DhlTtOGeFQVCkNXG1E3asuXMN22dux07YMf+G+Xxz6zcM6DCAb279Rm/aasnADgNZl7SOv6z5C6P+O4rVR1frKagdaTvYf2Y/vfx70clTyyqmFqbWm7JpKGaDSM6rpzLeSuJPx+s5XrhwkV19bHWtFwpzPt08ZIl5bKod6Ts4mHWwwe8zpSCF00Wna5SfyD9R5YJvDWmFafpnfizHthXV5ijKz9WPKP8oTp27kNZMyk3CIA1c3flqoOkiiIELBzJr1awG73cs5xiVxkqg/jz+m9ve5G8b/saBs9b3EbKWvJI8Np/Y3Kh9zSkmiWwR9TkNpb4IYh5Q28QDBaZ1isZibuq6fDmUl8OWLdrr9u0vWgcB6AYBmkm0c2gHgL2dPdP6TGPT9E1M6zOt1kOM7zYeDycP5o+dT2evzpQZypgTN4cQjxA+3/c5v576lRsib6Cjp6bxhyM/0P719mw5ueVS3jGgDfth7nx3It+6CEJKyZvb3qwRcZRWljLi8xG8/tvrepn5onyq4JRuRJaYL4zm3Lu5HuJI9hGM0lglzXMxisuLOVdxrsbAiVJK0grTyCzOxCiNVh8vrTCNnn49CXIPsnlLpuoGkXI+RZ+Eyvy5DegwgHYO7ZrEIArLCjmSfYQv939ZYxyxssqyelNHlt9jXWkaozSy/MhyAH45+csl663O7LWzGf3V6EalW3PO59DeuT3QuDSTwWho1gnC6jOIQCllDTs2lXWxmaIrAbNBmNm0SXuMi9Miibr6QpgNorDxEwZN6jWJgmcKeCzuMTZP38xXt3zFyC4jGRw6mD0Ze3B3cmd23GxCPEIQCBbEL6DMUMYX+75o9DnNnDl3Rr+jstYgTuSf4G8b/sbtS2/X7yRBGw6ktLK0Ss/w1IJUYrxiAFh9dHWNY5kvjF19ugLanWH2+Wy9/FR+PeZcDfOfvbpB5JbkUlpZSqWxUn+v1pBamEpo+1C6+nS95BRTcXlxrZGNGbNmfzd/evn3okJW6BHdzrSdONs70yewDwFuAZw9f+kGYTYFozTy6tZXq+jovaA31/33ujrN1LLpdl0X2B1pO/Se4b+cqt0gcktyq0Qj1nIq/xSLDizCIA01fh8Go+Giow3kluTSy78X0PCWTFJKYj6Oof2/2jPi8xEsP7y8SmQspWRn2k6bpq7qMwiveta5NLWQK4pOpkZhcXFan4iNpkrVwYO1x7rSTOY0VNGljetirrQOcg/irr53IYRgcKh27kcHPoqPiw+O9o4EewQjkbg6uvJD4g+XnGoy/9nDvMKsroMwt8ralb6Lf//+b718R9oO4EK+3mA0cLroND3b96RPQB82n6yZEjDn03WDKM2rUpl8qsB6gzhTrOXDs89nV/nTWkYh1t4xlhvKOVN8htD2oUT6RNYaQaQXpjPzh5lWXWSeXv80MR/F1Pl9VYkgTDMYmhsn7EjfQUxwDE72TgS4BVy0DkJKybs736133C7zZzw2ciz/++N/ZBRlUG4o59ZvbyUpN4ltqdv4bO9nte57MOsgYV5hCIRuAtVZdngZTvZOTOw+kV9P/UrWuSw+iv+oyvcy7ptxdHuvGz5v+DQohfd/O/4Pg9Tu4E/mn6yybtGfi+i7oG+NqGhvxl56vNeDxOxEisqL6O3fG6j/95CYnUhpZWmVsuO5x/njzB8M7TiUM8VnuPW7W3lu03P6+o8TPmbwp4OJ/iiaTSc2Wf2eGkJ9BhEvhHigeqEQ4n4gwSZqrhT8/WHWLHjnHYiI0DrJAQzVKobrTDPVkmJqKm7reRu39LiF/zf0/+llnTw74eroyvs3vk9+ab4++ueX+75k3rF5nCs/x/7M/Xx/8HurzmG+27qp202cOXemSsuh4vJiZq2cVSPXa76zHdpxKP/Y/A+9E9eOdM0gTuSdoNJYSUZxBgZpIMA5gAEdBrAnY0+NeogaKaaSvCoj41a/ANSH+c9eaaykqPzC95FedKFVkzUX893puzmacxSJpGP7jnT16UpmcWaNdMZ3B7/js32fcf3/rq81Mll2eBn/2fEf7Zind3Pm3BnWHV9XYzuoahA9/XoC2oW4wlBB/Ol4/WbB39W/1hSTURpZn7SeckM5u9J3MXvtbOI+ieOr/bXPApCYk4idsOOZYc9glEZ2pu9k2eFlbE3Zyhc3f8GITiN4ZsMzfHfwO07mn6xiSgezDtIvqB9+rn5kFmdyNOcoi/9cXOO9jwofxU3dbiLrfBajvhrFQ6sf0kcNyCzOZEfaDkZ2GUlReRH7z+yvVWd1SipK+GTPJ4wOHw3U/H3sTNuJRFZJaxmlkUfWPEJiTqKe9jJHEHUZRHJeMn0W9OEvq/9SpXx98noAPrjxAw795RBDQofo42PlleTx901/p29gX85XnOfp9U/bpIK+PoOYA9wrhNgihHjHtPwCzAT+2uRKriSEgA8/1EZ27an9QXF0hNhY7XldEYQNDSLMO4xlU5fh5+qnlz034jk+n/g503pPo71zez6M/5D/7v8v9/5wLz+c/oF+H/ZjwMIBTFkyhbe2vVXleAajoUaUcDDrIL4uvvoFyPIPt+nEJj7e8zHX/vdant34rF6elJeEk70T30/+HjcnN+774T4MRgO/p/6Os70zFcYKUgpS9BZM/s7+RAdFk3U+q0aaJft8Ni4OLoS015pw5pVqBuFs70yQe1CDIgjLP7tlmuliEUS5oZxP93xKXonWhHjoZ0O5efHNAIS2D6WzV2eg5jhY29O249XOi6M5R3l0zaOAlv4wR1jv7nqX5zc/T4WhQo/Uvj7wda3azZ+Dq6MrHs4eBDgHcCjrEAfOHqC0spS4kDgALcVkMoh9mfuInB/Je7ve45kNz3D9/67nzW1v8mPij9gLe2KDY7nvx/vIOZ/D1398TezHsXrqIzEnkS5eXRgUMggHOwd2p+/mt5TfcHdy544+d7Bg3AKcHZyZumQqYf8JI+DtAH499SvlxnKO5Rwjyj+KIPcgMosz+ddv/+KOpXfoulIKUjiRf4KxEWP1llfmaMZ8MTV3Av37CG10WvPvosJQweqjq3ln+zssTFhYo6nz9tTtnKs4x1/j/ko7h3Y1DMJsNL+l/qaXfbX/Kz26/S1FK+/g0QGvdl51GsRrW1+jwljB5/s+rzI21vrk9XT27EykTyQOdg70DeyrR5f//PWf5JXm8eXNX3LwkYMsmbJEzww0JXUahJTyjJRyKPAScNK0vCSlHCKlbJ2NelsiZoMICgI/P3BzgxO1pF/KyrQFLqkOoiGM6zaOKVFTcHZw5oGYB1h5dCXTV0xnYMhAXuj1AjklOdze+3amRE3h6Q1PEzE/gjH/G0NeSR6zVs0iYn4EKxNXAtqdVfzpeKICogj3Dge0tMbHCR9TbihnX+Y+BIJpvafx+m+vsy1lG6DdXYV5hdHBowPzx87n97TfeXDlg6QXpXNT95sALRQ3V1AHOAcQE6zVQ5iHkUgrTGPCoglsOLEBP1c/vNpp2dP80nwOZx+mu193wrzC9BxzuaGcQQsHsfTQUqSU3Pj1jXyc8DFSSl799VU2Jm+0yiAsUyJSSk6cO8G1X17L/Svv58P4Dzmee5xKYyVJedpFPrR9KB3ba/VTls2LpZRsS9nGjV1v5I4+d7DxxEaklNy57E6mLdUaI5jTGT8d/4mSyhL8Xf35IfEHCstq/layS7Kr3Ah0ce3CwayD+oXNbOABbgFknc/iXPk5pi2dxsn8kzz202O8tf0tXB1dWbhnISsSVzCi8wj+M/Y/VBor+SHxB975/R32ZOzRL6CJ2Yl09+2Oi6MLvQN6E58Rz/bU7cSFxOFg50BUQBQpc1L4ZcYvfDjuQwB+T/2d1POpGKSBKP8ogj2CySjOYG/mXiRSr2MyRwnDOg0j0ieSCO8IJnSfQGxwrB7x/nT8J4Ldg7k27Foc7RxJL0znTPEZOs3rxPhF43ly/ZM8uOpBPt/3eZXPaeOJjTjYOXBV56vo7NmZkwUnkVJSZihDSqkbkdkIAN7b/R79g/oT5R/FtlTtN+zr6qsZnGm4jeO5x/W+OifzT/Ll/i+5p989+Ln6cdeyu5i1chYbkzey6cQmRoeP1i/83Xy7kVuSS875HJYdWcaE7hPoH9QfF0cXunh1qfE9NwXWTBi0WUr5rmmxTaLrSsZsEB06aJFF164XUk6WmKMGf39tzKbKhlW2XSpvjX6LfbP2MW/MPFZNW8VI/5HkPJ3DV7d8xf9u+R/PjXiOwaGD2XJyC0M+HcKnez/FzcmNO5fdyeqjq3l87ePszdzL5F6TCfMOA+DxdY8za9UsVhxZwd7MvXT17crCmxYS4hHC7LWzMRgNJOUlEeETAcAdfe7ggZgH+Gyflq++u+/dgNYU0nxBDXAOoF9QPwRCvxt7e/vbrDy6kn2Z+/B388fJ3glXR1c9xdTdtztdvLrod4g70naw+/RulhxeQkpBCj8d/4nH1z3O67+9znObn+PdXe9WaZNf3SBCPEJwc3TTTSSvJI9O8zpxX/x9ekOAIzlH9Fy4r4svYDIIU+ux1MJU9mbs5dovryX+dDwZxRkM6ziMwSGDOXvuLAezDrIzfSd/nPmD/NJ83Yw+3fspAM9d9RyllaU8svqRGimprHNZVQyis1tnjmQf4afjPxHkHqQ3t/V39dc6Xa68n8TsRNbetZZXr32VJwY/wacTPiWlIIVDWYeY0G0CMcExhHmF8ca2N3Rj3payDaM0cjTnKN19uwMwIHiA3pza3NcGtBZ4V3W+ilkDZhHiEcLBrIMkndOMs19QP4Lcg0gpSNGjo1XHtL4u21O34+roSt/Avggh2DNrD0smL2F0+Gh+T/ud/NJ8fk76mbGRY7ETdnTw6MDp4tPsydhDZnEm793wHnl/yyPEI0S/oJvZeGIjg0IG4eHsof8+/vfH/7j191vZfXo3BWUFdPftTnJesjaWlpQczTnK8I7DiQqI0ptR+7r46hGQlJKpS6Zy87c3YzAa+DBeM8RXr32VD8Z9QFF5EYv+XMSor0ZRWFbI6IjRuh5z3dnu07s5mX9Sj/RsiTUd5RS2xGwQwcHaY1QUHKzZRFOPGkK09Igt0kz1IYSgX1A//jr4r/i7+QNaE1sAR3tHXrn2Fb6+9Ws+n/g5iTmJxATHsP+h/bg5uTF+0Xjm75rPX+P+yl8G/gV/V39cHV31fP3G5I3sy9xH/6D+uDm58dbot9iTsYelh5eSlJtEhHeEruHD8R/yYMyDRHhHMCZiDG6ObnoE4ebohruDO+5O7nT17crezL0UlhXy2d7PmBo1lf/e/F/eGKVNhujdzpvMc5mcyD9BD78edPbsTGphKgajgZ+Tfga0HPPOdG347dLKUv6+SUtRHDh7gMziTNyd3AGq9MVIK0wjpH2IfkEAzXDSCtOY0XkGiY8mEhcSR2J2ol7BvvqO1fz7+n/j2c5Tbz2WWpDK2uNr2XxyM7cvvR3Q5ig3393P2zGPSmMlZYYyfjr2k37+1UdXIxDMjJ7J3OFzWfznYgYuHFilwjr7fNUIoqt7V0orS1l1dBXDOw3X71gD3AIAWPznYp4Z/gyjwkfx7IhneWfMO9za81b8XbXfwYTuExBCMLnXZI7mHMXBzgF/V3+2pW4jrTCNksoSuvuZDKLDAArLCjFKYxWDsKR3QG/NIIqTcLZ3pptvN4Ldg8kszqTCWEGQexA/J/1MWWUZ21K36ZEIQHvn9jjaO3Jd+HVUGit5dM2j5Jfmc0PkDQCEtA8hvTBdb0V3S89b8GrnxbBOw9ieuh0pJcsOL+NQ1iHiT8dzXdh1ALpBLD+ynPOG8zyz4RkAHhn4CKCZYfb5bArLCon0iaSXXy/9/fi4+NDTrye70nfx0i8vsSdjD8XlxRzJPsJvKb8xsMNAQtuHMqnXJFIfTyX9iXQm9ZqEdztv/fwAXX01g1hyaAkA/YP61/r5NSXKIJqbHj20R0uDSE2tmUaqbhCXKc3UUO7ocwebp29mzR1rCPcOJ/HRRH6+62eWT12uD/shhCDCOwJfF1+GdxrOyqMrOZl/kuigaACm9p5KkHsQC+IXUFRepKekQDOlj276iKOPHcXZwZlIn0iO52kG0dGzY5VhRfZm7OXzvZ9TVF7EE0Oe4O5+dzMqXBtewtvFm9VHV2OURqKDouni1UWv7DYbxIn8E6w8upJ2Du2YN2YeQe5B3NPvHpLzkknKS9LnDq8eQYS2DyXIPUi/qzffUd8WehsdPTvSw68HR7KPcCz3GEHuQcSFxvH4kMcBzWyD3INILUzlaK7WOiY5LxkPJw96B/QmKiAKN0c3/rv/v/o5zb3hg92DMUgD4d7huDm58dp1r/H95O9Jzkvmx8QLo+NUN4hrA67l1xm/8tOdP7Fg3AK93GwQ10dczyvXvFLle3ayd+LZEc9yS49b9AhvStQUAMZ1Hceo8FH8lvKb3oKph5/2OzePBwYXUlnVifKP4lDWIY4VH6N3QG8c7BwIcg/S1z899GmKy4tZeXQl+zP3M6zjsBrHGNZxGM72znx94GtGdBrBuG7agJUdPDpwuug0J/JO6HVPAENDh5JSkMKSQ0u47bvbiP4oGqM0VjGI7PPZetpq88nNCAR3970bFwcXtqZs1Q0/0idSr5gGLcX08jUvE+gWyEu/vKRHjL+l/EZCRgJDQqv24vdw9uD7yd+T8f8y8HX11cvDvcOxE3Z65bcyiCsBDw947TWYMUN7HaVddDh0qOp2ZkMIDdUeL3ME0RBGdhlJoHsgoN3RjY4Yzc09btYjDoAPxn3AqjtWMannJP1CajYIO2HHxO4T9c555gjCEvOxIn0i9RSTOX9vPtapglM8vu5xhnUcxqCQQVX2927nTUFZAYNDBzOxx0S9cjjhdEKVO8dv//yW2OBYHot7jPQn0rmlxy2AVn/S3a879sK+pkF4hBLsEaxHEHsy9hDhHYG7gxZxdPftTkFZAVtTtuppA0s6enYkrTCNYznH6OnXExcHF4Z0HIK9nT0Odg4MDBlIhbGCXv69EAjWHFuDQOgX6D6BffRjTeg+gU6enfRUhlEaOXvubBWDsBf2jOg8grGRY6uUX93lal4a+RKLbluEvZ19DZ1zBs9h2dRl+uuY4Biev+p5Xhz5IsM7DSejOIP5u+YDFwyid0BvnOydiPKP0uuCqhMVEKUN/VLwB/0C+wGa+QG4ObrxYOyD+Lv6c/fyuzFIQ62RiIujC/+89p+8ft3rbJq+CVdHV0Cb1/100WmS85MJ8w7Tf0fmY8xeOxsPJy2l5NXOSzcxc46/qLyIqPbafzTCJwJvF28GhQxiZ/rOWg3C0c4RN0c3/Fz9+H7y9/i6+LJg3AI8nT1ZuGchpZWldRqls4NzlddO9k508epCbkkugW6BVUzTViiDaAnMnQuDTBewXqY7j1ZsEDVIStIMsPxCmmN4p+EMDh3MdeEXQmjLOyLzhRioEkFUp6tPVxJzEok/HV9lu/HdxhPlH8XfR/ydFbevqLGfj4sP9sKeD8d9iJ2wo7OnZhCv/PoKEsnc4XOxF/ZUGCv0XK+dsKN3QG/9GMHuwfi5+pF9PptvDnzDvB3zKCov0iIItwsppr2Ze4kOjtb3M18sj+ce14f9sKRj+45aBJFzlGEdh/Hz3T8zf+x8ff3gEO2CMiZiDJE+kZRUltDZq7M+PIa53T1ouf0HYh5g44mNHM89TvzpeIrKi6qM0VUXro6u/OPqf+Dj4nPRbUFLAb58zcv0D+qv39WvOrqKxwc/rl/MnOydmBk9k5nRM+s8jvkzNkgD/YI0gzDv3y+oH25Obvwy4xc6eHTA0c6xzgvsk0Of5Jnhz+jpJ9AiiKLyIv448wdhXmF6ef+g/rg4uJBZnMldfe9i76y9HHj4gH6RtqwEfqLrEzjYOejmNbDDQPZl7uNQ1iHshB1dvLrQ1bcr9sIeX1dfPaqNC43j7FNnmRw1mQEdBpCQofUWqEt/bZibaF+O6AHA4eKbKC4rYWHQrl3NeohWkmKqlXXrtBnznn76ggGaiPKPItAtEDthp0cdANeEXYOnsycFZQV6pXZtjOs2jk0nNzGu6zgeGvAQh3ZrxtrLvxd/PlJ3L9dnhj/DXX3v0i9AET4RDA4dzK70XQS7B3N1l6vpHdCb/Wf2V/kDh3uH4+royvmK8wS5B2kGUZLNkz8/qUdCoe1DKTeUk1+aT2ZxJsl5ydwffb82ihkXDAKoPYJo35EfE3+kwlhBN99uDO80vMp6893uyC4jOZl/kmO5x/TtOnh00NNoZmZGz+SlX15i/s75uDm64WDnwPhu4+v8bJqC3gG96eDRgWEdh/H29W9XWffBuA/q3dcyPaNHEB5aBGGOMnv69yThwQRSClLwdvG2Wpd5lNrjuce5Pvx6vdzR3pFBIYP45dQvzIqdhaujqx51wAWD6OnXk3D3cBbftlivExgUMohyQznLjyynk2cn3VTMzVMtMUcsg0IGsfHERjp4dCC0fajV+rv6dGUta5VBXLHY22sV19UNwtyLupkqqS8J89AheTXnYBBC8NTQp2r0InWyd+KWnrfwW8pvVf6o1RneaTg7778wj/MhDtW5rSXV79qc7J34febvlFSUUGmsxMHOgbiQOPaf2U9c6IXWInbCjij/KHaf3k2gWyC+rr7sy9xHRnEG/QL7sf/Mfnr49aCkUpuJzdwGPzo4Wh/iMqS91srpXMU5/SJjSUfPjlQYtT4E5jtGS8Z1G8fyqcsZ32088afjWX5kOd19u+Pv5k/6EzWHHw/2CObuvnezcM9C/F39GdllpNVRQWOxt7Pn2GPHcHFwaXD7fHcndzp7duZUwSn6BvYFtE6bvQN6c1O3m/TtvNp51ZmmqosOHh3059VvPB4Z+Ah9A/vqNw2WBLoF4t3OmzERYwC4rddt+jpzvUpiTmIVc57WexrnK87XqsOc8hwcOrhBn4/5hkIZxJVMVNSFAfzMtOYUk9kYajEIoErvbUveu+G9yzJ5jiUujhdGkXks7jG6eHWpUrcB2t3x7tO79Qji11O/AvDxTR/T1acr3i7eejRhrkCODormcJo2bpSdsKO7X3f2ZOypM4IwU5tB2Ak7bu6hda7rE9Cnzu0seXbEs3y5/0tSC1OZO3xu/R9CE1GfsV+MfkH9KCsr06ODdg7tOPDwpY/UamkQ1VOXU6Km6PU41RFCEP9gPIFugezeXnXa3s6enfF39SfrfBaR3hdShi+MfKH6YXTiQuK0up9OIxqk/+ouV9PJs1OD92ssqg6iJRIVBWlpVS+ohYVadBFoSsO0IYOoCzcntyppp8tN74DezB0xt8YdnvmiHOQehJ+LVqnrZO9Ev8B++gXNXLew6ugqOnh0qPE+zP0CzC2ALDH3hbATdvXWv4AWQXX16co1Xa6pd7tIn0im9Z6mNQDoMbHebVsC88bM45WoVy6+YQOpEkF41Z26rA1z67DqCCH0KKK2OqXaCPYIZt9D+/RmstbSN7Avp+ac0kcDsDUqgmiJjBqlVVx/8gkMNDULLCzUhgP38LjwurXQSINoqUzvPx07YUcPvx56q5+Y4JgqrU66+XbjyF+OsDVla60X+bv63oVXOy+9L4Ul5giis2fnGi1ZqhPsEczRx47Wu42Z9258j1mxs6pcJFsqYd5hRLpbd7FtCB7OHng4eVBUXlRv3VZDGdRhEGuOrbHaIIAqDR5aKiqCaIkMGACjR8Pbb+OUna1V8ubng6cnODlpS2uMIHKtH/66JePj4sNfB/8VIYRuELX1au3u1537Y+7n2rBra6y7seuNdVbWBrkH4WDncNG0UUPxaufFiM6XJzXRkglpH4J3O+8G11/Uxw1db8CrnZc+zEtbQUUQLZXnn4errmLI1KlgNIKLizYMB2iRRGsyiHoqqVs75o5MDWmqeDHs7ey5NuxafRRRRdMS5hWGp7Nnkx5zUMgg8v7W9n7fyiBaKiNGdiwudwAAH9tJREFUwP33k5WURICrK6xerRkDaGkmlWJqEQwJHcKQ0CFVhkRoCtbdVftQ3YpLZ8G4BQ2eOOhKRRlES2bhQg5t2UJAdLRWF2GeaMjDo3VFEG3YILr6dmX7zO3NLUPRAMy95hUXRxlEa8DTE/buBQfT1+XhcaFfhC0wGmHNGrjxRrC7xGoqg+GC1jZoEApFW8amldRCiLFCiEQhxHEhxDO1rJ8hhMgSQuwzLfdbrJsuhDhmWqbbUmerwM0NnE0tWmJiYOtWbbEFmzbBTTdpaa1LxdLIlEEoFK0KmxmEEMIeeB+4AegFTBNC9Kpl02+llP1NyyemfX2AF4A4YBDwghDC+v70bZ1XX4XwcLjzTsjIACm1CMNY+8TvDSZJG4dfnyv7UjCbgrNz3a2YVqyAb7+99HMpFIomxZYRxCDguJQyWUpZDiwGrO2hMwZYL6XMlVLmAeuBsTbS2frw8IBFiyAnR4smRo7UHr/8sv79jhyBbdvg9Ona15snIUoxTXe5qQnmhzK3YAoLqzuCePllbWkq9u6tfVY+hULRIGxZBxECpFq8TkOLCKpzmxDiKuAo8LiUMrWOfWt0HRRCPAg8CBAYGMiW6sNTNIDi4uJL2t9W1KfL7d13iXrxRRz37AEPD/I//5yDYVrnn8B16+iwahXlXl6cuuceznfqxNBbbsGhpASjoyO/L16MfXk5IUuXkvzgg7Q/fJi+Tz3Fri+/JHzXLgIBDhxg2/LlVHjXDN6s/by8ExLoB+R4euJbVsav69ZhdLbo/GU0MuLQIRCCrZs3a7PqXQLFxcWcv+ceDO3akfDRR5d8vKakNf7GmhOlq+E0uTYppU0WYBLwicXru4H3qm3jCzibns8CNpmePwk8Z7Hd88CT9Z0vNjZWXgqbN2++pP1txUV1lZVJWVQk5QMPSOnpKWVFhZTffSelEFJ27y6li4uUd94p5bp1UoKUjz+uPX74oZSPPqo937xZymee0Z5/952UI0ZoxwIpv/225jnXr5fH/vIX697Ad99pxzGfKz296vrkZK0cpDx7tuq6efOknDjRuvOY2Lxpk5Tt2mnH27SpQfvamlb7G2smlK6G0xhtQLys47pqyxRTOmA5ylmoqUxHSpkjpSwzvfwEiLV2X4UJJydwd4frr9cqhD/7DO66C4YOhT17YMoUrbJ59Wpt23/+EyIjYfFibQH49VfYbmqqefgw/P/2zjw+qurs47+HkLCLrBEIMYkJsshaRBQtRBEFMShKwboWtVZEau0ivli0tq9AXUqLKFQqaKGg4AIqQUEtsgflJZGdsMkSAkRiRJAlnPeP3z3cO5OZZAJkZiDP9/PJZyZ37syce2bm+Z1nOefs2AH07s1QVqAw06hRSJ40KbSchw0rpaT4/m9Zv969v32772MzZgCzZwP795f9Pg5VDx3int0A8PzzIT9PqUQcP+6zN8kp9uzhb0Y5RUUKxEoAaSKSLCJxAAYBmOM9QUSaeP7NAGCtxccAeolIPSc53cs5pgTjuutYkvrww5xQ9+67QM2aQL9+zAP885+cfFezJnDbbVwt9sABisannwJZWXydNWuA3buBSy5hbmPePI7vLceOAcuWIebo0eC5DC/+AuGfqPZujOQViGPHmEsAmDcJkbgCZ3/otm2BzEzNRSgleeABYMCAkseffprVe8opKkwgjDEnAAwFDft6AG8bY9aKyLMikuGcNkxE1opINoBhAO5znvstgD+DIrMSwLPOMSUY9eoBV1zBUf0//gE05n7C6NWLGxD9+CNwA9eyR//+vG3YEBg8mB7Ejz9SLD7/nHMXEhOBjAx6Ezk57vusWgUc4V4H2Ly57HYdPAjExrr7WATyIGo7C9bt2OEez8kBjjrO5eLFIXdDNSsQgwbxdlNoC9kplYhNmzgQ8mfHDlYFFheHv01RSoXOgzDGzDXGtDDGXGKM+V/n2EhjzBzn/pPGmDbGmPbGmHRjzAbPc183xqQ6f5Mrsp3nDU8+CfzP/7jGEeD8iZ7OJia9nB20Lr8cuOwy4MEH6XlYbrmFXgUAXHwxR1MiDPNYvvjCvR+KQBQWUrxsojuQQHTuDFx4oa8HYT2a5ORyzfc45UHYVXB37Qp84p//zFCcUvkoKgLy80se372b3rL9Dim6mut5xc03c46Ef+XO448D997LsAvAx3NyeO41zuqeiYmukNj/4+OBrl19BWLRIiAtDcVxcaF7EMEEwhiGmFq1ApKSfAVixQq+/6BB9Fp++CGkLjglEJ2dPZeDCcTcuQxBRRPr10eXcTKGAwJviPF84Lvv+H3y/07ZkOm+feFvU5SiAlEZSE8HpkzxXTZDhH/x8ZxD0asXDbXFrvvUrx8N9M6ddL0XLQJ69MCPTZuWTyDq1uX7eQVi717+WFu3LikQWVlAly4UsBMnXI+iDKoVFDC5Xq8ery2YQGzezHzIofDuWBcUY4Arr6RnN2EC8POfAx98ENk2vfUW0L17uXJA5wR2dr/Xizh82J2zE8i7qKSoQCgcJb78sisQDRowNAUAt97K23feAVau5I+re3ccTkgoKRB//zsNvdfoHjzI8FFMDEXCKxDLlvG2TRtXIIzhTO4NGygQV11FYQnRSMUdOAA0dTbEad48sEAcPOiO1O2kwEhTWMi+3b+fhQbTpwPTpkW2Ta+9xtto6aOzQXGx+/30CoG34EI9iFOoQCjuOk8NGgCNGrneAwC0aAG0b8/R5LRpTHj37YsjzZrRkNuEXkEBMHIkE33eGd3WgwCA+vXpiVjGjaMRv+Ya5jx++IFhn27d+JwBAygqLVuG7EHEffst0MQpjktICCwQdikRwE2MnzgBPPJI4ORlOLDG6uWX6aV17UoPK1Js2eKWOJ9PBtO7CrIKRJmoQCi+DBwI3HST77FBg4Dly4E332Seo25dHElIYJWRNfhjxvDHl5LCKqqTJ5n0277dLXHNyADmzAHWrgVWr2ap7aOPcpXapCSec9NNFKElS4BLuW8zunRhTiKEWHi1ggLXgwgmEF7Px46Oc3KAV15h8joSWGOVmgpcfTWFMy/PfTw3l2XHtoigonn9dYYkY2LOr5CLd/HIYAJxOtdbVAQ895y7XM15ggqE4su4cSWN5MCBvC0q4gKBAAUCoLFdupSicPfdXFNp0yZ6AhMmUCgGD+a5I0awpHXIEGDYMHouDz7Ixzp0oDDcdx/nP3jzIVdcwVGdtwzW8sEHTL47AhJXUODrQRQWlswz5ObyNibGfU3robz/fvkTxWcjiWuN0kUX8bZJE1+BWLiQf/Pmnfl7hUJmJgXpoosqh0Dsdubh1q59eh7ErFn8fq9ceWbtizJUIJSySU6mka5XjzOsARxOTOQIc9gwehWJicCLLzIslJxMQz9hAtC3r+tBNGzIMtwvvqAIjB7N/ATg5i4mT3ZDUpYrnCW8srKA7Gx3prQxLO1ds4bGbPp0TuDzehBASS9i82aO0Js3dz2IrCyG2Y4dA6ZODb1vFi2iUTnTCXnWWMXH8/aii+iR2Uobew0VtcS7P7t2cYvbxo0DC8SqVefmfIHSPIiaNTlB9HQEws4VOs/CUyoQSmhMnuwu1wHgWP36HDVVrcpjmZkUgLg44OOPefzAAYaQvPzud4xt790LDB3q+1hMTOD3btuW3sWLL9LTsF5HZibDVS+9xHDU/ffzuPUgmjurtfgLRG4uQzmJia4HsXIlcO21nD8xaVLoXsHMmayAmT/f97gx9G6OHw/tdfLzef0NGvheg81D2GvwzkMpi7lz3cqc8nD0KJPlzZpRsPwFYt064Cc/4QDgXKM0gWjaNPD1hoIKhFKpadWKZZhebr2VP4xvvuHIy5KWRkP2yiu+cysAGsH0dLdKKhRiY1mKm5VFAZo6lbOr//IXeglDh9Ko25nXoXgQqalMjH/zDUfqa9cy1zFkCD2S0jZLys5mrqSwkGIIlKyymjePOZexY0O7xr17WSBgS5GtQNgwk831bNgQmhHasYNtHDSo/PuE2Hi8FQj/97P7hEyfXr7XjQbsXu5NmpQMMTVrRo+pvEbeGFcgyrFu2LmACoRyZojQgPuTlsZyzbO13Hb37gzlLFrEUfZPf8rE+bPP8v07d3Y9C+s5WKH46CPOGP/oIxr1AwfYvsREGoasLP7Iu3RhjiU5ma8bzIt49VWOzp94gvmWmJiSAjFrFm/HjuWI+6qrUGfjxuDXl5/vhpeAkgKxa5d7PaEsPWJj4R9/TA+rPFhBTUhwR9Tevli4kLdLlgSfZxKtWA+iRYvgHkR5BSIvz81bqQehKBHg6aeBrVtpxP/2N6BdO4aqfvEL95yXXsLXzz3n5jyqV+eofNYsntu3r+vptGpFD6K4mAsbAgwvxcYyT7JyJXDHHSU3YSouZiIb4AKIAPMtW7awYmvqVI5SZ8+ml7JnD9u8bBkalbZOv79A2GS1DTHt3MlcT40aXC+rLFau5LX07g0880z58gU2YWs9iGPHXMNqDAXCepMzZ4b+uuWhqAixpxMeK4tAAmGMKxCNGzNkGOLMfQC+a5WVx4M4fDjqZ6mrQCjnBtWq0dgDrJZavZqJaS+1aqHAPwyWnMyk96pVwFNPAX360Kj16ePO93j1Vc71sK9/zz1c8fazz2j8s7JoWObOZcVWfj7w0EM8t3lzN/fRuzfb1q0bR5RjxgAdOzIPkZiIul5DYnfBsPgLRMOGzOPk5VFwiooofH36MPZf1n7hX37Jaxo4kMbOVm6Fgr8HYdsH0Bs6cIAronboALz9duivWx6GDkW7P/zh7L/ud9+5ZdVFRSx4KCzkApQ2xASULw9hP9dLLw3dgygqopcY5WG6itxRTlEiz5QpNAhpaTTWXtLSGALr1InzMyxxcfQ6ioooAC++SAPywQcc2Verxr0m8vNpJDt14rENGziyXraMFTE33kjv4dtvgenTUef55zlqrFkT+OtfgX/9i88R4WtZrwFgLiI+ngJhR/TNm1OYtm+ngGVnu3NFvJw8CXz1FT2gdu14LCcn8LkLF6KGf5ho927miC64wNdgXnqpG17q3p1e05gxNLLVq4f6iYTG8uWovWULvRenMOK0MYZ5kyZN+JnWresrfDYv0ayZu7Lwvn2uJ1oWOTn8bFq0CH3W+ebNfN8VK7isSpSiAqGc33jnU/iTksKRdqtWDN34c8EFwC9/CbzwAv/v3p0G8uabud7Te++5595wA0Vk7lwKSmwshaBmzVMT9qqMHs28SXo6k+q5uTQuyclMsHs9CICCsXevm6BOSKBxmzOHBmnq1MAT+7Zs4Ui5c2deW0wM38d/D4SdO4Hrr0en6tVZKda+PY/v3s33smt1Ae7IeMECGtKUFApucTGT+nZxRH+MKSl+9vUmTGBop08fJvQtjscjdtmVd94BPvyQwlvenFZhIYsp/vtffn4JCfxcvQJhvYWkJLeSrjy5hOxsCnHjxvw+hYItiw5lPbMIoiEmpXLTqVNgcbAMG0YPpFs3jkI//5zVWf68/z4rl6pWZfL68cd9H+/WDUaE1V05OW7I57PPSs6BsNjJct6QD8BYeY8eDO8EimHbBPXll3Nk36IF8PXXJc974QXAGO4R3rOnO0t71y53/w6vIT14kKGt226jobYemd3YKRAjRtDwHjjAUNv8+Qzxde7M3MjkyaxC81ZarV3rXteGDRSHFSvKFyazvPcexSE1lQUF331HkbWClZfnLhKZlOR6TKEuc3L0KNtoBWL//tDyClu38lYFQlHOYZo3p8H98EOOLnv0cA21FxHf1XL9qVsXhy65hCLz9ts8t1mz8gmENdoAvYFNm1zDX1DA0WteHkNX1atzlVyAxsub/9i3j5VQr70G3HUXckaNogGfNImP25JPgLmQKlXYxpkzGfK5+24+lpzM0XgwgcjOZijt6FHmbqZM4arBP/sZH//ySy7psXMnvYNf/Yqz7r1tzclhvgkoOYt86VKWJZdWxrt2LfvinnvYN3v2UCBsscLmzSwJrlGDOaimTTl5M8S1v7BhA5fXaNeOzz9xIrS5J9aD2LYt9LkyEUAFQlHKokMHd8b3GbC/e3ca5tGjKTQZGQxZWQEIFGLav59GJD7eNxbfvz8N9+TJNMRt29JjaNqUXsro0fRmAD62bRsNtC3lvOYahoeGD8cPqamcJPjKKxSAPXtcEYyJoUjk5zOk1bIlJ8kBfP8OHXwF4tAheg2XXUYxqF+f4balS1lym5DA+2vW0HvLyKABHz4cmDiRVWPz5wO1auFow4YUJTu/xV8gxo1jgcFXXwXv9HXr2Gabf1mzhgJRrx5H/Bs20IO4+GKKvB0EBNqLPRBWzKwHAVCA7d7uWVkUYjv732I9iOLiqN4WVwVCUcLEN3feCYwfT4N4//00yocOAf/+N0/wF4imTRmusIbVS+PGjN2PHUsjLULP4amnWLH161+759pE9eDBfI+XXmIZ7vr1ruF89FGO5CdN4ijY6600bsxZ64sW0Xvw5gE6dqSRzMzk3JSEBC5a16QJE/RvvUUhWLKE4bmePZnIv+ACPr9OHU7oW7yYhvvkSXpYbdvih6QkegAAr/Xzz11De/KkO2HPu6GVP2vXcjn51FT+f+wY3wfgtW/cSIGwi0UCnDOzbVtJwz1smDsx0pKTQ+Fu0cIViFmz3D1OrriCeSz/5Vu2bXM/01DDTLNm+c6kN8Z3va4KQAVCUcKFCEMiRUWsXElP54g1M5PGpWFD3/MHDOBIPy/P14BZZsxgmeTw4TSwgwczaW13DrRYgahXj5VYv/kNR+7eKp2+ffkeNnfiFaTkZIpHRgYnP3rp2JGVWf36MTQ1cCDFYP58vld6Ovf0WLyY1VzeLW4td9zB21GjKCZOmw/bCY/16rHfjhxxDWRODr2r2Fh3Xoo/33/PqqLWrX1n+ltxCiYQ117LWytAAHMS48aVzD/l5FCAqlZ1y6SnTGG7JkzgZxQf7zt3pbiY3oXdIz4UgThyhCXXd91FkTt4kKG6pk1DD4edBioQihJubKVMgwYMtyxbxmod/7WoGjRgCOqzz1hW60+tWlxKY9QoGvFgJCZy3sKMGYHzJwAN3McfMxwD+IrHa68xQTx7dsmFFG2iukEDehgTJ1IQvHj/t8bXS//+vMaHHnL3CW/blgtCAkxo2+VZ7MS8BQt4+9hj9BJyczmizsx09/tYv563bdrQa7AG3HoQLVtSZAoKGGKytGpFD+jdd3nte/YwSQ7wGr05j5wcV4CtB5GbSy/poYcomD16MFFuk9d79tDIX345Q5ehCERmJqu7du6kUHXr5grj0qVlP/80UYFQlEjSpQs3B7L19/6I0DiWJgBlIUJDd/31pZ/XogXLcJcv9/VC4uN9R+Be2rRheOrDD92lQPyxAtGyZeBz7DVWqcIQVt++QN++OGyNdufOLBceMIAhK7s4YuvWrkfz8MN8vE8fTlg8csQNT9lkvQ0zeUNMFq8HIUIhy8xkeOhPf3IF4uBB1LJVT/v20bOwAuH1AL1rkKWnUxSsENjQVUoK5+Js2lSyT7Zt457xVoxmzuTrd+jABS+3bAE++YSfTXZ2yeefJVQgFEVxqV7dXV49FGJiuBeITVwHomlTPu4/DyMQDRsyNJWUhO/T0jg3o18/PnbffQwbjRxJz6pnTwrnyJGsdJo9m7mdzZt5bN06TmC03lBaGm+9HoTFP4T3zDO8rhtv5Eh9yZJT62OdmhFvq6usQMTFucUMXjFOT+etDTPZBLUViPXrWclUUEBxBlgq/dRTFCY7SbN/f4pVtWrcvCs9nf1TgQKhE+UURal4Qp1A5qG4dm3XCAPMx6SkcCJiUhJH0gCN5siR9Czq1KFovfACcw0tW7qhO+tB2BxEUhJzBceP+4aY7LmPPsoR+rx59BaGDAFmz8aFOTn0CB5+mCE37yTBxo056vceS0ujSC5YwLBTbi69pcREJuj/8x96PuvW8XXHj+fkQIDitGsXw0sDBlAUCwvdmevt23Mv+OPHAy+aeYaoQCiKcm5QpQo3iJo4kRU9NokNUATq1OH9sWNp2MeNY2WVxT/EVLUqj23dWrKCzNK7N0fsR48yFHjwIOrPmcP8QVERjb63BPrKK3l+VY9pFaEX9Oqr9CwWLqRHFRvLYoXCQk4WTE1l/uORR/hYu3b0ihYupDDatce8y5q0a8d8xsaNLC0+y2iISVGUc4cHHuDERf8Rv5caNbhc+4EDHF1bunenF+Jdk6tDB+Yigk1yrFPHrTbq2hXIyEDMkSMcuc+fXzIcN2UKBcyfsWOBP/6RYaZ+/ZjfsAwZwgmPq1Yx11CjBsNp999Pw79iBfDb3/qKjsUuj+KdXHgWUQ9CUZTzE/+qMDuJ0Mu4cQxNlcbvf89Ji6mpQFoaFjZqhB6BynVLIy6OovXEE4E3y2rTxr3dupW5mD17GOZq1Mh3WXsvLVvytbOzK2TRPxUIRVEqLw0auNu8BuPqq/lnCbY1biiEspOiXScqMZHeRZcuwdcLi41llVYFJapVIBRFUaKV8ePLPuf228u3wVE5UIFQFEU5lxkxosJeWpPUiqIoSkBUIBRFUZSAqEAoiqIoAVGBUBRFUQKiAqEoiqIERAVCURRFCYgKhKIoihIQFQhFURQlIGLsLkfnOCKyH8COM3iJhgAOnKXmnE20XeUjWtsFRG/btF3lI1rbBZxe2y42xjQK9MB5IxBnioh8aYzpXPaZ4UXbVT6itV1A9LZN21U+orVdwNlvm4aYFEVRlICoQCiKoigBUYFw+WekGxAEbVf5iNZ2AdHbNm1X+YjWdgFnuW2ag1AURVECoh6EoiiKEhAVCEVRFCUglV4gRORGEdkoIrkiMjyC7WguIp+LyDoRWSsiv3aOPyMiu0VktfPXJ0Lt2y4iXztt+NI5Vl9E5ovIZue2XpjbdKmnX1aLSJGIPBaJPhOR10Vkn4is8RwL2D9C/uF853JEpFOY2/W8iGxw3vs9EbnQOZ4kIkc8/TahotpVStuCfnYi8qTTZxtF5IYwt+stT5u2i8hq53jY+qwUG1Fx3zNjTKX9AxADYAuAFABxALIBtI5QW5oA6OTcrwNgE4DWAJ4B8Lso6KvtABr6HfsrgOHO/eEAxkT4s9wL4OJI9BmAnwLoBGBNWf0DoA+ATAACoCuAFWFuVy8AVZ37YzztSvKeF6E+C/jZOb+FbADVACQ7v9uYcLXL7/EXAYwMd5+VYiMq7HtW2T2ILgByjTFbjTHHAMwA0C8SDTHG5BljVjn3vwewHkCzSLSlHPQD8IZz/w0At0SwLdcB2GKMOZPZ9KeNMeYLAN/6HQ7WP/0AvGnIcgAXikiTcLXLGPOJMeaE8+9yAAkV8d5lEaTPgtEPwAxjzFFjzDYAueDvN6ztEhEB8DMA0yvivUujFBtRYd+zyi4QzQDs9Py/C1FglEUkCUBHACucQ0MdF/H1cIdxPBgAn4jIVyLyS+dYvDEmz7m/F0B8ZJoGABgE3x9tNPRZsP6Jpu/dYHCUaUkWkf8TkYUick2E2hTos4uWPrsGQL4xZrPnWNj7zM9GVNj3rLILRNQhIrUBvAPgMWNMEYBXAVwCoAOAPNC9jQRXG2M6AegN4BER+an3QUOfNiI10yISByADwEznULT02Ski2T/BEJERAE4AmOYcygOQaIzpCOBxAP8RkQvC3Kyo++z8uAO+A5Gw91kAG3GKs/09q+wCsRtAc8//Cc6xiCAiseAHP80Y8y4AGGPyjTHFxpiTAF5DBbnVZWGM2e3c7gPwntOOfOuyOrf7ItE2ULRWGWPynTZGRZ8heP9E/HsnIvcB6AvgTseowAnfFDj3vwLj/C3C2a5SPrto6LOqAPoDeMseC3efBbIRqMDvWWUXiJUA0kQk2RmFDgIwJxINcWKb/wKw3hjzkue4N2Z4K4A1/s8NQ9tqiUgdex9Mcq4B++pe57R7AcwOd9scfEZ10dBnDsH6Zw6Ae5wqk64AvvOECCocEbkRwB8AZBhjDnuONxKRGOd+CoA0AFvD1S7nfYN9dnMADBKRaiKS7LQtK5xtA9ATwAZjzC57IJx9FsxGoCK/Z+HIvkfzH5jp3wQq/4gItuNq0DXMAbDa+esD4N8AvnaOzwHQJAJtSwErSLIBrLX9BKABgE8BbAawAED9CLStFoACAHU9x8LeZ6BA5QE4DsZ67w/WP2BVyXjnO/c1gM5hblcuGJu237MJzrm3OZ/vagCrANwcgT4L+tkBGOH02UYAvcPZLuf4FAC/8js3bH1Wio2osO+ZLrWhKIqiBKSyh5gURVGUIKhAKIqiKAFRgVAURVECogKhKIqiBEQFQlEURQmICoSiRAEi0kNEPox0OxTFiwqEoiiKEhAVCEUpByJyl4hkOWv/TxSRGBE5JCJ/c9bo/1REGjnndhCR5eLuu2DX6U8VkQUiki0iq0TkEufla4vILOFeDdOcmbOKEjFUIBQlRESkFYCBALoZYzoAKAZwJzib+0tjTBsACwE87TzlTQBPGGPagTNZ7fFpAMYbY9oDuAqctQtwdc7HwDX+UwB0q/CLUpRSqBrpBijKOcR1AH4CYKUzuK8BLox2Eu4CblMBvCsidQFcaIxZ6Bx/A8BMZ02rZsaY9wDAGPMjADivl2WcdX6EO5YlAVhc8ZelKIFRgVCU0BEAbxhjnvQ5KPJHv/NOd/2ao577xdDfpxJhNMSkKKHzKYDbRaQxcGov4IvB39Htzjk/B7DYGPMdgIOeDWTuBrDQcCewXSJyi/Ma1USkZlivQlFCREcoihIixph1IvIUuLNeFXC1z0cA/ACgi/PYPjBPAXDp5QmOAGwF8Avn+N0AJorIs85rDAjjZShKyOhqropyhojIIWNM7Ui3Q1HONhpiUhRFUQKiHoSiKIoSEPUgFEVRlICoQCiKoigBUYFQFEVRAqICoSiKogREBUJRFEUJyP8DTY0SSZ5KBvoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-VGQ2pMavm4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "ea271102-b038-4cd5-dbf4-6457aa858e0c"
      },
      "source": [
        "x = list(range(len(train_accuracies)))\n",
        "ax = plt.subplot(111)\n",
        "plt.plot(x, train_accuracies, 'r', label=\"Train\")\n",
        "plt.plot(x, val_accuracies, 'g', label=\"Validation\")\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.grid()\n",
        "leg = plt.legend(loc='best', ncol=2, mode=\"expand\", shadow=False, fancybox=False)\n",
        "leg.get_frame().set_alpha(0.99)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oktkpkuqjet"
      },
      "source": [
        "### Exercise 6\n",
        "\n",
        "*   What do you observe in the previous graphs?\n",
        "*   At which epoch is it interesting to retrieve the model parameters for inference?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwhRt39yzug-"
      },
      "source": [
        "... # To complete.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XK_eUsq3avm8"
      },
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UREO5elavm8"
      },
      "source": [
        "We can finally evaluate our model on our test set and compare with the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UZPvzjxlusr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f53390b4-c57e-4f2e-b91f-41d80a8dce9c"
      },
      "source": [
        "valid_loss, valid_acc = evaluate(neural_net, val_loader, device)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.52163   Acc: 165/209 (78.947%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPWvDM-qavm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289f5270-44db-4d4e-a8c1-04574fdfb2f1"
      },
      "source": [
        "test_loss, test_acc = evaluate(neural_net, test_loader, device)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Eval:  Avg_Loss: 0.50438   Acc: 166/209 (79.426%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvP_-KUwqjez"
      },
      "source": [
        "### Exercise 7\n",
        "\n",
        "* Compare validation and test metrics.\n",
        "* Do you think the chosen features are informative of the fate of the passenger?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov4CKUFh5tun"
      },
      "source": [
        "... # To complete.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rueFjis6YlLN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}